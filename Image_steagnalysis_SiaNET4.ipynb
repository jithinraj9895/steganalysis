{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_steagnalysis_SiaNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4I2V/mkx5gbkXoZOw+oYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinraj9895/steganalysis/blob/main/Image_steagnalysis_SiaNET4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7dv2INO5zEY",
        "outputId": "d1c3a99b-ae28-4d0f-fef0-a93c763b1871"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqaWulTIOq5P"
      },
      "source": [
        "from datetime import datetime\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "def set_random_seed(seed=None):\n",
        "    \"\"\"Sets random seed for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = (\n",
        "                os.getpid()\n",
        "                + int(datetime.now().strftime(\"%S%f\"))\n",
        "                + int.from_bytes(os.urandom(2), \"big\")\n",
        "        )\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Using a generated random seed {}'.format(seed))\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.set_rng_state(torch.manual_seed(seed).get_state())\n",
        "\n",
        "\n",
        "def get_random_seed():\n",
        "    return np.random.randint(2 ** 31)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "175OQ-IlQ9RG"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class RandomRot(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        rot = random.randint(0, 3)\n",
        "        return {\n",
        "            'image': np.rot90(sample['image'], rot, axes=[-3, -2]).copy(),\n",
        "            'label': sample['label'],\n",
        "        }\n",
        "\n",
        "\n",
        "class RandomFlip(object):\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self._p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if random.random() < self._p:\n",
        "            return {\n",
        "                'image': np.flip(sample['image'], axis=-2).copy(),\n",
        "                'label': sample['label'],\n",
        "            }\n",
        "        else:\n",
        "            return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if image.ndim == 3:  # HxWxC\n",
        "            image = image.transpose(2, 0, 1)\n",
        "        else:  # NxHxWxC\n",
        "            image = image.transpose(0, 3, 1, 2)\n",
        "        return {\n",
        "            'image': torch.from_numpy(image).type(torch.FloatTensor),\n",
        "            'label': torch.tensor(label).long()\n",
        "        }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZxEAYoPQrcI"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CoverStegoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, cover_dir, stego_dir, transform=None):\n",
        "        self._transform = transform\n",
        "\n",
        "        self.images, self.labels = self.get_items(cover_dir, stego_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.images[idx]))\n",
        "        image = np.expand_dims(image, 2)  # (H, W, C)\n",
        "        assert image.ndim == 3\n",
        "\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'label': self.labels[idx]\n",
        "        }\n",
        "\n",
        "        if self._transform:\n",
        "            sample = self._transform(sample)\n",
        "        return sample\n",
        "\n",
        "    @staticmethod\n",
        "    def get_items(cover_dir, stego_dir):\n",
        "        images, labels = [], []\n",
        "\n",
        "        cover_names = sorted(os.listdir(cover_dir))\n",
        "        if stego_dir is not None:\n",
        "            stego_names = sorted(os.listdir(stego_dir))\n",
        "            assert cover_names == stego_names\n",
        "\n",
        "        file_names = cover_names\n",
        "        if stego_dir is None:\n",
        "            dir_to_label = [(cover_dir, 0), ]\n",
        "        else:\n",
        "            dir_to_label = [(cover_dir, 0), (stego_dir, 1)]\n",
        "        for image_dir, label in dir_to_label:\n",
        "            for file_name in file_names:\n",
        "                image_path = osp.join(image_dir, file_name)\n",
        "                if not osp.isfile(image_path):\n",
        "                    raise FileNotFoundError('{} not exists'.format(image_path))\n",
        "                images.append(image_path)\n",
        "                labels.append(label)\n",
        "\n",
        "        return images, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91278fr58-s"
      },
      "source": [
        "import torchvision\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Sampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "\n",
        "class TrainingSampler(Sampler):\n",
        "\n",
        "    def __init__(self, size, seed=None, shuffle=True):\n",
        "        self._size = size\n",
        "        self._shuffle = shuffle\n",
        "\n",
        "        if seed is None:\n",
        "            seed = get_random_seed()\n",
        "        self._seed = seed\n",
        "\n",
        "    def __iter__(self):\n",
        "        yield from itertools.islice(self._infinite_indices(), 0, None, 1)\n",
        "\n",
        "    def _infinite_indices(self):\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(self._seed)\n",
        "        while True:\n",
        "            if self._shuffle:\n",
        "                yield from torch.randperm(self._size, generator=g)\n",
        "            else:\n",
        "                yield from torch.arange(self._size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "\n",
        "    def __init__(self, sampler, group_ids, batch_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sampler (Sampler): Base sampler.\n",
        "            group_ids (list[int]): If the sampler produces indices in range [0, N),\n",
        "                `group_ids` must be a list of `N` ints which contains the group id of each\n",
        "                sample. The group ids must be a set of integers in [0, num_groups).\n",
        "            batch_size (int): Size of mini-batch.\n",
        "        \"\"\"\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of torch.utils.data.Sampler, \"\n",
        "                             \"but got sampler={}\".format(sampler))\n",
        "\n",
        "        self._sampler = sampler\n",
        "        self._group_ids = np.asarray(group_ids)\n",
        "        assert self._group_ids.ndim == 1\n",
        "        self._batch_size = batch_size\n",
        "        groups = np.unique(self._group_ids).tolist()\n",
        "        assert batch_size % len(groups) == 0\n",
        "\n",
        "        # buffer the indices of each group until batch size is reached\n",
        "        self._buffer_per_group = {k: [] for k in groups}\n",
        "        self._group_size = batch_size // len(groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in self._sampler:\n",
        "            group_id = self._group_ids[idx]\n",
        "            self._buffer_per_group[group_id].append(idx)\n",
        "            if all(len(v) >= self._group_size for k, v in self._buffer_per_group.items()):\n",
        "                idxs = []\n",
        "                # Collect across all groups\n",
        "                for k, v in self._buffer_per_group.items():\n",
        "                    idxs.extend(v[:self._group_size])\n",
        "                    del v[:self._group_size]\n",
        "\n",
        "                idxs = np.random.permutation(idxs)\n",
        "                yield idxs\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError(\"len() of GroupedBatchSampler is not well-defined.\")\n",
        "\n",
        "\n",
        "def build_train_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        RandomRot(),\n",
        "        RandomFlip(),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "    size = len(dataset)\n",
        "    sampler = TrainingSampler(size)\n",
        "    if stego_dir is not None:\n",
        "        batch_sampler = BalancedBatchSampler(sampler, dataset.labels, batch_size)\n",
        "    else:\n",
        "        batch_sampler = BatchSampler(sampler, batch_size, drop_last=False)\n",
        "    epoch_length = math.ceil(size / batch_size)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        worker_init_fn=worker_init_reset_seed,\n",
        "    )\n",
        "    return train_loader, epoch_length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_val_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "    sampler = SequentialSampler(dataset)\n",
        "    batch_sampler = BatchSampler(sampler, batch_size, drop_last=False)\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "    return test_loader\n",
        "\n",
        "def worker_init_reset_seed(worker_id):\n",
        "    set_random_seed(np.random.randint(2 ** 31) + worker_id)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz1SmXalPkzz"
      },
      "source": [
        "set_random_seed()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdGRqGq_P7NN"
      },
      "source": [
        " train_cover_dir = \"/content/drive/MyDrive/boss_256/256_cropped_train/cover\"\n",
        " train_stego_dir = \"/content/drive/MyDrive/boss_256/256_cropped_train/stego\"\n",
        " val_cover_dir = \"/content/drive/MyDrive/boss_256/train/cover\"\n",
        " val_stego_dir = \"/content/drive/MyDrive/boss_256/train/stego\"\n",
        " \n",
        " \n",
        " train_loader, epoch_length = build_train_loader(\n",
        "        train_cover_dir, train_stego_dir, batch_size=32,\n",
        "        num_workers=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1c-rr7UsJqR"
      },
      "source": [
        "val_loader = build_val_loader(\n",
        "    train_cover_dir, train_stego_dir, batch_size=32,\n",
        "    num_workers=0\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgLZk_7xavka"
      },
      "source": [
        "train_loader_iter = iter(train_loader)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mCyjXydT3yp"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import Parameter\n",
        "\n",
        "\n",
        "srm_dir = \"/content/drive/MyDrive\"\n",
        "SRM_npy = np.load(os.path.join(srm_dir,\"SRM_Kernels.npy\"))\n",
        "\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    return (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class SRMConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, stride=1, padding=0):\n",
        "        super(SRMConv2d, self).__init__()\n",
        "        self.in_channels = 1\n",
        "        self.out_channels = 30\n",
        "        self.kernel_size = (5, 5)\n",
        "        if isinstance(stride, int):\n",
        "            self.stride = (stride, stride)\n",
        "        else:\n",
        "            self.stride = stride\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = (padding, padding)\n",
        "        else:\n",
        "            self.padding = padding\n",
        "        self.dilation = (1, 1)\n",
        "        self.transpose = False\n",
        "        self.output_padding = (0,)\n",
        "        self.groups = 1\n",
        "        self.weight = Parameter(torch.Tensor(30, 1, 5, 5), requires_grad=True)\n",
        "        self.bias = Parameter(torch.Tensor(30), requires_grad=True)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.numpy()[:] = SRM_npy\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.conv2d(input, self.weight, self.bias, self.stride, self.padding,\n",
        "                        self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class BlockA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockA, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BlockB(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockB, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes, stride=2)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "        # self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.shortcut_conv = conv1x1(in_planes, out_planes, stride=2)\n",
        "        self.shortcut_bn = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # out = self.pool(out)\n",
        "\n",
        "        identity = self.shortcut_conv(identity)\n",
        "        identity = self.shortcut_bn(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbvp0KdThp7"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class KeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer=None, zero_init_residual=True, p=0.5):\n",
        "        super(KeNet, self).__init__()\n",
        "\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.srm = SRMConv2d(1, 0)\n",
        "        self.bn1 = norm_layer(30)\n",
        "\n",
        "        self.A1 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.A2 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.AA = BlockA(30, 30, norm_layer=norm_layer)\n",
        "\n",
        "        # self.B1 = BlockB(30, 30, norm_layer=norm_layer)\n",
        "        # self.B2 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B3 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "        self.A3 = BlockA(64, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B4 = BlockB(64, 128, norm_layer=norm_layer)\n",
        "        self.A4 = BlockA(128, 128, norm_layer=norm_layer)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # self.bnfc = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # self.fcfusion = nn.Linear(128, 128) #4\n",
        "        self.fc = nn.Linear(128 * 4 + 1, 2)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.bias, 0.2)\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "        if self.zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, (BlockA, BlockB)):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        x = x.float()\n",
        "        out = self.srm(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.A1(out)\n",
        "        out = self.A2(out)\n",
        "        out = self.AA(out)\n",
        "\n",
        "        # out = self.B1(out)\n",
        "        # out = self.B2(out)\n",
        "\n",
        "        out = self.B3(out)\n",
        "        out = self.A3(out)\n",
        "\n",
        "        out = self.B4(out)\n",
        "        out = self.A4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), out.size(1))\n",
        "\n",
        "        # out = self.relu(out)\n",
        "        # out = self.bnfc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, *args):\n",
        "        ############# statistics fusion start #############\n",
        "        feats = torch.stack(\n",
        "            [self.extract_feat(subarea) for subarea in args], dim=0\n",
        "        )\n",
        "\n",
        "        euclidean_distance = F.pairwise_distance(feats[0], feats[1], eps=1e-6,\n",
        "                                                 keepdim=True)\n",
        "\n",
        "        if feats.shape[0] == 1:\n",
        "            final_feat = feats.squeeze(dim=0)\n",
        "        else:\n",
        "            # feats_sum = feats.sum(dim=0)\n",
        "            # feats_sub = feats[0] - feats[1]\n",
        "            feats_mean = feats.mean(dim=0)\n",
        "            feats_var = feats.var(dim=0)\n",
        "            feats_min, _ = feats.min(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)\n",
        "\n",
        "            '''feats_sum = feats.sum(dim=0)\n",
        "            feats_sub = abs(feats[0] - feats[1])\n",
        "            feats_prod = feats.prod(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)'''\n",
        "            \n",
        "            #final_feat = torch.cat(\n",
        "            #    [feats[0], feats[1], feats[0], feats[1]], dim=-1\n",
        "            #    #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            #)\n",
        "\n",
        "            final_feat = torch.cat(\n",
        "                [euclidean_distance, feats_mean, feats_var, feats_min, feats_max], dim=-1\n",
        "                #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            )\n",
        "\n",
        "        out = self.dropout(final_feat)\n",
        "        # out = self.fcfusion(out)\n",
        "        # out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, feats[0], feats[1]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzhXzdCFWHh8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin=1.25):  # margin=2\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        label = label.to(torch.float32)\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3VifExXUbMj"
      },
      "source": [
        "criterion_1 = nn.CrossEntropyLoss()\n",
        "criterion_2 = ContrastiveLoss(margin=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty1kf2kGYmgT"
      },
      "source": [
        "net = KeNet();"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTokfBpUXydL"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    net.cuda()\n",
        "    criterion_1.cuda()\n",
        "    criterion_2.cuda()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2W6WHALZB8H"
      },
      "source": [
        "from torch.optim.adamax import Adamax\n",
        "\n",
        "optimizer = Adamax(net.parameters(), lr=0.001, eps=1e-08, weight_decay=0.0001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvtWoO5xqMMV"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.3,\n",
        "                                                           patience=10, verbose=True, min_lr=0,\n",
        "                                                           eps=1e-08)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTdhQ_wXZ177"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "import shutil\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def preprocess_data(images, labels, random_crop,gpu):\n",
        "    # images of shape: NxCxHxW\n",
        "    if images.ndim == 5:  # 1xNxCxHxW\n",
        "        images = images.squeeze(0)\n",
        "        labels = labels.squeeze(0)\n",
        "    h, w = images.shape[-2:]\n",
        "\n",
        "    if random_crop:\n",
        "        ch = random.randint(h * 3 // 4, h)  # h // 2      #256\n",
        "        cw = random.randint(w * 3 // 4, w)  # square ch   #256\n",
        "\n",
        "        h0 = random.randint(0, h - ch)  # 128\n",
        "        w0 = random.randint(0, w - cw)  # 128\n",
        "    else:\n",
        "        ch, cw, h0, w0 = h, w, 0, 0\n",
        "\n",
        "\n",
        "    cw = cw & ~1\n",
        "    inputs = [\n",
        "            images[..., h0:h0 + ch, w0:w0 + cw // 2],\n",
        "            images[..., h0:h0 + ch, w0 + cw // 2:w0 + cw]\n",
        "        ]\n",
        "\n",
        "    if gpu:\n",
        "        inputs = [x.cuda() for x in inputs]\n",
        "        labels = labels.cuda()\n",
        "    return inputs, labels"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMPL0h7NaYje"
      },
      "source": [
        "def train(epoch):\n",
        "    net.train()\n",
        "    running_loss, running_accuracy = 0., 0.\n",
        "\n",
        "    for batch_idx in range(epoch_length):\n",
        "        data = next(train_loader_iter)\n",
        "        inputs, labels = preprocess_data(data['image'], data['label'], False,gpu=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "   \n",
        "        outputs, feats_0, feats_1 = net(*inputs)\n",
        "\n",
        "            # count parameters start\n",
        "            # print('parameters_count: {}'.format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
        "            # count parameters end\n",
        "\n",
        "        loss = criterion_1(outputs, labels) + \\\n",
        "                   0.1 * criterion_2(feats_0, feats_1, labels)\n",
        "\n",
        "        accuracy1 = accuracy(outputs, labels).item()\n",
        "        running_accuracy += accuracy1\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            running_accuracy /= 10\n",
        "            running_loss /= 10\n",
        "            \n",
        "            print(\n",
        "                'Train epoch: {} [{}/{}]\\tAccuracy: {:.2f}%\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx + 1, epoch_length, 100 * running_accuracy,\n",
        "                    running_loss))\n",
        "                    \n",
        "            ###############################log per log_interval start\n",
        "            is_best=False\n",
        "            save_checkpoint(\n",
        "                {\n",
        "                    'iteration': batch_idx + 1,\n",
        "                    'state_dict': net.state_dict(),\n",
        "                    'best_prec1': running_accuracy,\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                },\n",
        "                is_best,\n",
        "                filename=os.path.join(\"/content/drive/MyDrive/dataset\", 'checkpoint.pth.tar'),\n",
        "                best_name=os.path.join(\"/content/drive/MyDrive/dataset\", 'model_best.pth.tar'))\n",
        "            ###############################\n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "            net.train()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYQb3yVrVCL"
      },
      "source": [
        "def valid():\n",
        "    net.eval()\n",
        "    valid_loss = 0.\n",
        "    valid_accuracy = 0.\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            inputs, labels = preprocess_data(data['image'], data['label'], False,gpu = True)\n",
        "\n",
        "            outputs, feats_0, feats_1 = net(*inputs)\n",
        "            valid_loss += criterion_1(outputs, labels).item() + \\\n",
        "                              0.01 * criterion_2(feats_0, feats_1, labels)\n",
        "            valid_accuracy += accuracy(outputs, labels).item()\n",
        "    valid_loss /= len(val_loader)\n",
        "    valid_accuracy /= len(val_loader)\n",
        "    print('Test set: Loss: {:.4f}, Accuracy: {:.2f}%)'.format(\n",
        "        valid_loss, 100 * valid_accuracy))\n",
        "    return valid_loss, valid_accuracy\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtT-ktcdb_k4"
      },
      "source": [
        "epoch = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mAaeRXveb85B",
        "outputId": "f55bc059-9adf-4c68-e119-b847f9d3e488"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename, best_name):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, best_name)\n",
        "\n",
        "\n",
        "_time = time.time()\n",
        "best_accuracy = 0.\n",
        "for e in range(1, 100 + 1):\n",
        "    logger.info('Epoch: {}'.format(e))\n",
        "    logger.info('Train')\n",
        "    train(e)\n",
        "    logger.info('Time: {}'.format(time.time() - _time))\n",
        "    logger.info('Test')\n",
        "    _, accuracy1 = valid()\n",
        "    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "        scheduler.step(accuracy1)\n",
        "    else:\n",
        "        scheduler.step()\n",
        "    if accuracy1 > best_accuracy:\n",
        "        best_accuracy = accuracy1\n",
        "        is_best = True\n",
        "    else:\n",
        "        is_best = False\n",
        "    logger.info('Best accuracy: {}'.format(best_accuracy))\n",
        "    logger.info('Time: {}'.format(time.time() - _time))\n",
        "    save_checkpoint(\n",
        "        {\n",
        "            'epoch': e,\n",
        "            'state_dict': net.state_dict(),\n",
        "            'best_prec1': accuracy1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        },\n",
        "        is_best,\n",
        "        filename=os.path.join(\"/content/drive/MyDrive/dataset\", 'checkpoint.pth.tar'),\n",
        "        best_name=os.path.join(\"/content/drive/MyDrive/dataset\", 'model_best.pth.tar'))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch: 53 [30/157]\tAccuracy: 69.06%\tLoss: 0.581537\n",
            "Train epoch: 53 [40/157]\tAccuracy: 65.00%\tLoss: 0.600882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3309b1189132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-07221aee318d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-9135b000e896>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (H, W, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}