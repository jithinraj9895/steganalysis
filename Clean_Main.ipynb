{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean_Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLIrzuZkLlhHBFf44eHc4e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinraj9895/steganalysis/blob/main/Clean_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaZ5s4J-e-tC",
        "outputId": "e24efe8c-edf4-4ef6-c74f-680dd59d9819"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3HtXI0JxJC"
      },
      "source": [
        "   from torchvision.datasets import ImageFolder\n",
        "   from torchvision.transforms import ToTensor\n",
        "   import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmdaV4_zKUMh"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch\n",
        "\n",
        "import os\n",
        "dir = \"/content/drive/MyDrive/mnist_stego\"\n",
        "\n",
        "dataset = ImageFolder(dir, transform= transforms.Compose([ transforms.Grayscale(num_output_channels=1), ToTensor()]))\n",
        "\n",
        "train_dl = DataLoader(dataset, batch_size=32,shuffle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xd6h73eiCgw",
        "outputId": "c8b16d78-977a-4be3-de11-7c7c110f0094"
      },
      "source": [
        "print(len(train_dl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxGSg476q58I"
      },
      "source": [
        "print(dataset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv9ss41RLqoa",
        "outputId": "64058431-df3c-407c-9356-195e131d4f85"
      },
      "source": [
        "data = next(iter(train_dl))\n",
        "inputs, labels = data\n",
        "\n",
        "print(inputs.shape)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
            "        0, 1, 0, 0, 0, 0, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef1fCcdBfOrP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL as image\n",
        "import pickle as pl\n",
        "\n",
        "srm_dir = \"/content/drive/MyDrive\"\n",
        "SRM_npy = np.load(os.path.join(srm_dir,\"SRM_Kernels.npy\"))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRV3meWgfREa"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFnOgDElfhYS"
      },
      "source": [
        "def activation(x):\n",
        "  a = torch.ones(x.shape)\n",
        "  a = torch.mul(a, 3)\n",
        "  return torch.where(x > -3,x,a)\n",
        "\n",
        "\n",
        "class the_tlu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(the_tlu, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return activation(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4kAMlksgM2F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.adamax import Adamax\n",
        "from torch.optim.adadelta import Adadelta\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import Parameter"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tgB-4SAhO52"
      },
      "source": [
        "\n",
        "\n",
        "class SRMConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, stride=1, padding=0):\n",
        "        super(SRMConv2d, self).__init__()\n",
        "        self.in_channels = 1\n",
        "        self.out_channels = 30\n",
        "        self.kernel_size = (5, 5)\n",
        "        if isinstance(stride, int):\n",
        "            self.stride = (stride, stride)\n",
        "        else:\n",
        "            self.stride = stride\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = (padding, padding)\n",
        "        else:\n",
        "            self.padding = padding\n",
        "        self.dilation = (1, 1)\n",
        "        self.transpose = False\n",
        "        self.output_padding = (0,)\n",
        "        self.groups = 1\n",
        "        self.weight = Parameter(torch.Tensor(30, 1, 5, 5), requires_grad=True)\n",
        "        self.bias = Parameter(torch.Tensor(30), requires_grad=True)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.numpy()[:] = SRM_npy\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.conv2d(input, self.weight, self.bias, self.stride, self.padding,\n",
        "                        self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class BlockA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None,activation = nn.ReLU(inplace=True)):\n",
        "        super(BlockA, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR-kU_0jj-fm"
      },
      "source": [
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    return (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymQw_QPj8M6"
      },
      "source": [
        "class BlockB(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockB, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes, stride=2)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "        # self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.shortcut_conv = conv1x1(in_planes, out_planes, stride=2)\n",
        "        self.shortcut_bn = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # out = self.pool(out)\n",
        "\n",
        "        identity = self.shortcut_conv(identity)\n",
        "        identity = self.shortcut_bn(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syGiDmSgkECX"
      },
      "source": [
        "class KeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer=None, zero_init_residual=True, p=0.5):\n",
        "        super(KeNet, self).__init__()\n",
        "\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.srm = SRMConv2d(1, 0)\n",
        "        self.bn1 = norm_layer(30)\n",
        "\n",
        "        self.A1 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.A2 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.AA = BlockA(30, 30, norm_layer=norm_layer)\n",
        "\n",
        "        # self.B1 = BlockB(30, 30, norm_layer=norm_layer)\n",
        "        # self.B2 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B3 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "        self.A3 = BlockA(64, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B4 = BlockB(64, 128, norm_layer=norm_layer)\n",
        "        self.A4 = BlockA(128, 128, norm_layer=norm_layer)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # self.bnfc = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # self.fcfusion = nn.Linear(128, 128) #4\n",
        "        self.fc = nn.Linear(128 * 4 + 1, 2)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.bias, 0.2)\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "        if self.zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, (BlockA, BlockB)):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        x = x.float()\n",
        "        out = self.srm(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.A1(out)\n",
        "        out = self.A2(out)\n",
        "        out = self.AA(out)\n",
        "\n",
        "        # out = self.B1(out)\n",
        "        # out = self.B2(out)\n",
        "\n",
        "        out = self.B3(out)\n",
        "        out = self.A3(out)\n",
        "\n",
        "        out = self.B4(out)\n",
        "        out = self.A4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), out.size(1))\n",
        "\n",
        "        # out = self.relu(out)\n",
        "        # out = self.bnfc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, *args):\n",
        "        ############# statistics fusion start #############\n",
        "        feats = torch.stack(\n",
        "            [self.extract_feat(subarea) for subarea in args], dim=0\n",
        "        )\n",
        "\n",
        "        euclidean_distance = F.pairwise_distance(feats[0], feats[1], eps=1e-6,\n",
        "                                                 keepdim=True)\n",
        "\n",
        "        if feats.shape[0] == 1:\n",
        "            final_feat = feats.squeeze(dim=0)\n",
        "        else:\n",
        "            # feats_sum = feats.sum(dim=0)\n",
        "            # feats_sub = feats[0] - feats[1]\n",
        "            feats_mean = feats.mean(dim=0)\n",
        "            feats_var = feats.var(dim=0)\n",
        "            feats_min, _ = feats.min(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)\n",
        "\n",
        "            '''feats_sum = feats.sum(dim=0)\n",
        "            feats_sub = abs(feats[0] - feats[1])\n",
        "            feats_prod = feats.prod(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)'''\n",
        "            \n",
        "            #final_feat = torch.cat(\n",
        "            #    [feats[0], feats[1], feats[0], feats[1]], dim=-1\n",
        "            #    #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            #)\n",
        "\n",
        "            final_feat = torch.cat(\n",
        "                [euclidean_distance, feats_mean, feats_var, feats_min, feats_max], dim=-1\n",
        "                #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            )\n",
        "\n",
        "        out = self.dropout(final_feat)\n",
        "        # out = self.fcfusion(out)\n",
        "        # out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, feats[0], feats[1]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75JIv1swkKYs"
      },
      "source": [
        "def preprocess_data(images, labels, random_crop, gpu):\n",
        "    # images of shape: NxCxHxW\n",
        "    if images.ndim == 5:  # 1xNxCxHxW\n",
        "        images = images.squeeze(0)\n",
        "        labels = labels.squeeze(0)\n",
        "    h, w = images.shape[-2:]\n",
        "\n",
        "    if random_crop:\n",
        "        ch = random.randint(h * 3 // 4, h)  # h // 2      #256\n",
        "        cw = random.randint(w * 3 // 4, w)  # square ch   #256\n",
        "\n",
        "        h0 = random.randint(0, h - ch)  # 128\n",
        "        w0 = random.randint(0, w - cw)  # 128\n",
        "    else:\n",
        "        ch, cw, h0, w0 = h, w, 0, 0\n",
        " \n",
        "    cw = cw & ~1\n",
        "    inputs = [\n",
        "                images[..., h0:h0 + ch, w0:w0 + cw // 2],\n",
        "                images[..., h0:h0 + ch, w0 + cw // 2:w0 + cw]\n",
        "        ]\n",
        "    if gpu:\n",
        "        inputs = [x.cuda() for x in inputs]\n",
        "        labels = labels.cuda()\n",
        "    return inputs, labels\n",
        "        \n",
        "    return inputs, labels"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbJpr35kP9x"
      },
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin=1.25):  # margin=2\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        label = label.to(torch.float32)\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWrAjBzGnulQ"
      },
      "source": [
        "model = KeNet(norm_layer=None, zero_init_residual=True, p=0.5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCfXKC1qkSx6"
      },
      "source": [
        "criterion_1 = nn.CrossEntropyLoss()\n",
        "criterion_2 = ContrastiveLoss(margin=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI4AfgRlk8O4"
      },
      "source": [
        "data = next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2b-vIu-mecy",
        "outputId": "157987b5-30d3-4901-eecd-5b08dea35fb0"
      },
      "source": [
        "imgs, label = data\n",
        "print(imgs.shape, label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 28, 28]) torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfLinZQImsQ5",
        "outputId": "e9f4c651-2595-4dc6-cbcf-bdc3da917d4a"
      },
      "source": [
        "inputs , labels = preprocess_data(*data,False)\n",
        "output, feat_0, feat_1 = model(*inputs)\n",
        "\n",
        "print(output,feat_0,feat_1)\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0570,  0.0979],\n",
            "        [ 0.0166,  0.0476],\n",
            "        [ 0.0298,  0.0207],\n",
            "        [ 0.0054,  0.0356],\n",
            "        [ 0.0506, -0.0063],\n",
            "        [-0.0585,  0.1010],\n",
            "        [-0.0357,  0.0741],\n",
            "        [ 0.0532, -0.0012],\n",
            "        [ 0.0062,  0.0508],\n",
            "        [-0.0571,  0.0979]], grad_fn=<AddmmBackward>) tensor([[0.1886, 0.2415, 0.4465,  ..., 0.1046, 0.2226, 0.2636],\n",
            "        [0.2070, 0.2435, 0.4370,  ..., 0.1660, 0.1074, 0.2305],\n",
            "        [0.1251, 0.2095, 0.4968,  ..., 0.0831, 0.1254, 0.1909],\n",
            "        ...,\n",
            "        [0.1428, 0.1893, 0.4391,  ..., 0.1197, 0.0586, 0.2107],\n",
            "        [0.1543, 0.2271, 0.4634,  ..., 0.1171, 0.1076, 0.2154],\n",
            "        [0.1882, 0.2416, 0.4465,  ..., 0.1048, 0.2223, 0.2636]],\n",
            "       grad_fn=<SelectBackward>) tensor([[0.1774, 0.2487, 0.4449,  ..., 0.1032, 0.2344, 0.2790],\n",
            "        [0.1539, 0.2143, 0.4542,  ..., 0.1332, 0.0598, 0.2136],\n",
            "        [0.1318, 0.2001, 0.4960,  ..., 0.0939, 0.1001, 0.1667],\n",
            "        ...,\n",
            "        [0.1623, 0.1735, 0.3709,  ..., 0.1550, 0.0174, 0.2275],\n",
            "        [0.2073, 0.2366, 0.4215,  ..., 0.1582, 0.1203, 0.2138],\n",
            "        [0.1772, 0.2489, 0.4448,  ..., 0.1035, 0.2342, 0.2792]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNWZtmSfDQ2o",
        "outputId": "9cfef33d-8ad6-45a9-802c-b7ac49bf7c30"
      },
      "source": [
        "print(feat_0.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XVw46tVEgq"
      },
      "source": [
        "optimizer = Adamax(model.parameters(), lr=0.001, eps=1e-08, weight_decay=0.0001)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv5-3J0oU-uA"
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Y7AadWsxE_"
      },
      "source": [
        "loss = criterion_1(output, labels) + 0.1 * criterion_2(feat_0, feat_1, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_wn4oBeUbX"
      },
      "source": [
        "#  VALIDATION AND TRAINING STARTS #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8XNYMUvTWtj"
      },
      "source": [
        "def set_random_seed(seed=None):\n",
        "    \"\"\"Sets random seed for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = (\n",
        "                os.getpid()\n",
        "                + int(datetime.now().strftime(\"%S%f\"))\n",
        "                + int.from_bytes(os.urandom(2), \"big\")\n",
        "        )\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Using a generated random seed {}'.format(seed))\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.set_rng_state(torch.manual_seed(seed).get_state())\n",
        "\n",
        "\n",
        "def get_random_seed():\n",
        "    return np.random.randint(2 ** 31)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0HIDrzL5lU"
      },
      "source": [
        "import torchvision\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "\n",
        "\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Sampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TrainingSampler(Sampler):\n",
        "\n",
        "    def __init__(self, size, seed=None, shuffle=True):\n",
        "        self._size = size\n",
        "        self._shuffle = shuffle\n",
        "\n",
        "        if seed is None:\n",
        "            seed = get_random_seed()\n",
        "        self._seed = seed\n",
        "\n",
        "    def __iter__(self):\n",
        "        yield from itertools.islice(self._infinite_indices(), 0, None, 1)\n",
        "\n",
        "    def _infinite_indices(self):\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(self._seed)\n",
        "        while True:\n",
        "            if self._shuffle:\n",
        "                yield from torch.randperm(self._size, generator=g)\n",
        "            else:\n",
        "                yield from torch.arange(self._size)\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "\n",
        "    def __init__(self, sampler, group_ids, batch_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sampler (Sampler): Base sampler.\n",
        "            group_ids (list[int]): If the sampler produces indices in range [0, N),\n",
        "                `group_ids` must be a list of `N` ints which contains the group id of each\n",
        "                sample. The group ids must be a set of integers in [0, num_groups).\n",
        "            batch_size (int): Size of mini-batch.\n",
        "        \"\"\"\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of torch.utils.data.Sampler, \"\n",
        "                             \"but got sampler={}\".format(sampler))\n",
        "\n",
        "        self._sampler = sampler\n",
        "        self._group_ids = np.asarray(group_ids)\n",
        "        assert self._group_ids.ndim == 1\n",
        "        self._batch_size = batch_size\n",
        "        groups = np.unique(self._group_ids).tolist()\n",
        "        assert batch_size % len(groups) == 0\n",
        "\n",
        "        # buffer the indices of each group until batch size is reached\n",
        "        self._buffer_per_group = {k: [] for k in groups}\n",
        "        self._group_size = batch_size // len(groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in self._sampler:\n",
        "            group_id = self._group_ids[idx]\n",
        "            self._buffer_per_group[group_id].append(idx)\n",
        "            if all(len(v) >= self._group_size for k, v in self._buffer_per_group.items()):\n",
        "                idxs = []\n",
        "                # Collect across all groups\n",
        "                for k, v in self._buffer_per_group.items():\n",
        "                    idxs.extend(v[:self._group_size])\n",
        "                    del v[:self._group_size]\n",
        "\n",
        "                idxs = np.random.permutation(idxs)\n",
        "                yield idxs\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError(\"len() of GroupedBatchSampler is not well-defined.\")\n",
        "\n",
        "\n",
        "def build_train_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = transforms.Compose([\n",
        "        RandomRot(),\n",
        "        RandomFlip(),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "    print(dataset.images)\n",
        "\n",
        "    size = len(dataset)\n",
        "\n",
        "    sampler = TrainingSampler(size)\n",
        "\n",
        "\n",
        "    batch_sampler = BalancedBatchSampler(sampler, dataset.labels, batch_size)\n",
        "    \n",
        "    print(batch_sampler)\n",
        "    epoch_length = math.ceil(size / batch_size)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        worker_init_fn= worker_init_reset_seed(0)\n",
        "    )\n",
        "    return train_loader, epoch_length\n",
        "\n",
        "def worker_init_reset_seed(worker_id):\n",
        "    set_random_seed(np.random.randint(2 ** 31) + worker_id)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK-DnUZ0UoMU"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "class CoverStegoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, cover_dir, stego_dir, transform=None):\n",
        "        self._transform = transform\n",
        "\n",
        "        self.images, self.labels = self.get_items(cover_dir, stego_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.images[idx]))\n",
        "        image = np.expand_dims(image, 2)  # (H, W, C)\n",
        "        assert image.ndim == 3\n",
        "\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'label': self.labels[idx]\n",
        "        }\n",
        "\n",
        "        if self._transform:\n",
        "            sample = self._transform(sample)\n",
        "        return sample\n",
        "\n",
        "    @staticmethod\n",
        "    def get_items(cover_dir, stego_dir):\n",
        "        images, labels = [], []\n",
        "\n",
        "        cover_names = sorted(os.listdir(cover_dir))\n",
        "        if stego_dir is not None:\n",
        "            stego_names = sorted(os.listdir(stego_dir))\n",
        "            assert cover_names == stego_names\n",
        "\n",
        "        file_names = cover_names\n",
        "        if stego_dir is None:\n",
        "            dir_to_label = [(cover_dir, 0), ]\n",
        "        else:\n",
        "            dir_to_label = [(cover_dir, 0), (stego_dir, 1)]\n",
        "        for image_dir, label in dir_to_label:\n",
        "            for file_name in file_names:\n",
        "                image_path = os.path.join(image_dir, file_name)\n",
        "                if not os.path.isfile(image_path):\n",
        "                    raise FileNotFoundError('{} not exists'.format(image_path))\n",
        "                images.append(image_path)\n",
        "                labels.append(label)\n",
        "\n",
        "        return images, labels"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7xayQfnPoxb"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "\n",
        "class RandomRot(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        rot = random.randint(0, 3)\n",
        "        return {\n",
        "            'image': np.rot90(sample['image'], rot, axes=[-3, -2]).copy(),\n",
        "            'label': sample['label'],\n",
        "        }\n",
        "\n",
        "\n",
        "class RandomFlip(object):\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self._p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if random.random() < self._p:\n",
        "            return {\n",
        "                'image': np.flip(sample['image'], axis=-2).copy(),\n",
        "                'label': sample['label'],\n",
        "            }\n",
        "        else:\n",
        "            return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if image.ndim == 3:  # HxWxC\n",
        "            image = image.transpose(2, 0, 1)\n",
        "        else:  # NxHxWxC\n",
        "            image = image.transpose(0, 3, 1, 2)\n",
        "        return {\n",
        "            'image': torch.from_numpy(image).type(torch.FloatTensor),\n",
        "            'label': torch.tensor(label).long()\n",
        "        }\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml7PWEMFP0b4"
      },
      "source": [
        "covr_dir = \"/content/drive/MyDrive/the_dataset/cover/\"\n",
        "steg_dir = \"/content/drive/MyDrive/the_dataset/stego/\"\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsZc7hMUwrN8"
      },
      "source": [
        "print(sorted(os.listdir(covr_dir)),\"==================\\n\",sorted(os.listdir(steg_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ukSmf-VLdP"
      },
      "source": [
        "train_loader, epoch_length = build_train_loader(\n",
        "        covr_dir, steg_dir, batch_size=32,\n",
        "        num_workers = 0\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4XE95M1Wwiq"
      },
      "source": [
        "train_loader_iter = iter(train_loader)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_fte8uykzXV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "datas =  next(iter(train_loader_iter))\n",
        "\n",
        "x, y = datas[\"image\"], datas[\"label\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OhGiwv3I6Tc"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah9WzsnbJ-37",
        "outputId": "964fc0bf-c92a-4e6b-b99f-2a07ea3f71d3"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLjGIZhrRjgT"
      },
      "source": [
        "if device.type == \"cuda\":\n",
        "  model.cuda()\n",
        "  criterion_1.cuda()\n",
        "  criterion_2.cuda()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8Ob1toJOCwu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cKIz_vxXHvz"
      },
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  running_loss, running_accuracy = 0., 0.\n",
        "  for batch in range(epoch):\n",
        "    data = next(iter(train_loader_iter))\n",
        "    img, lab = data[\"image\"], data[\"label\"]\n",
        "    inputs , labels = preprocess_data(img, lab, False,gpu= True)\n",
        "    optimizer.zero_grad()\n",
        "    output, feat_0, feat_1 = model(*inputs)\n",
        "    loss = criterion_1(output, labels) + 0.1 * criterion_2(feat_0, feat_1, labels)\n",
        "\n",
        "\n",
        "  #  the_accuracy = accuracy(output, labels).item()\n",
        "   # running_accuracy += the_accuracy\n",
        "   # running_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('EPOCH :',batch,\"LOSS:\", loss.item(), '\\n')\n",
        "    model.train()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gGd0KcAXUq6"
      },
      "source": [
        "def validate(epoch):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for d in range(epoch):\n",
        "      data = next(iter(train_loader_iter))\n",
        "      image, lab = data[\"image\"], data[\"label\"]\n",
        "      i, l = preprocess_data(image, lab,False,gpu = True)\n",
        "      if epoch == 1:\n",
        "        print(lab)\n",
        "      output, feat0, feat1 = model(*i)\n",
        "      for idx, j in enumerate(output):\n",
        "        print(torch.argmax(j),\"--\",lab[idx])\n",
        "        if torch.argmax(j) == lab[idx]:\n",
        "          correct += 1\n",
        "        total +=1\n",
        "  \n",
        "  print(\"ACCURACY :\", correct/total,\"total :\",total, \"correct :\",correct )"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fszWpUzio3H"
      },
      "source": [
        "train(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvtv_4w6wOB"
      },
      "source": [
        "validate(1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}