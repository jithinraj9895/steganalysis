{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean_Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtSAXK4KAdIsGv6IorczzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinraj9895/steganalysis/blob/second/Clean_Main_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaZ5s4J-e-tC",
        "outputId": "b1ded650-5162-42cf-f7cf-c833dbe50eea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3HtXI0JxJC"
      },
      "source": [
        "   from torchvision.datasets import ImageFolder\n",
        "   from torchvision.transforms import ToTensor\n",
        "   import torchvision.transforms as transforms"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmdaV4_zKUMh"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef1fCcdBfOrP"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL as image\n",
        "import pickle as pl\n",
        "\n",
        "srm_dir = \"/content/drive/MyDrive\"\n",
        "SRM_npy = np.load(os.path.join(srm_dir,\"SRM_Kernels.npy\"))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRV3meWgfREa"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFnOgDElfhYS"
      },
      "source": [
        "def activation(x):\n",
        "  a = torch.ones(x.shape)\n",
        "  a = torch.mul(a, 3)\n",
        "  return torch.where(x > -3,x,a)\n",
        "\n",
        "\n",
        "class the_tlu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(the_tlu, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return activation(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4kAMlksgM2F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.adamax import Adamax\n",
        "from torch.optim.adadelta import Adadelta\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import Parameter"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tgB-4SAhO52"
      },
      "source": [
        "\n",
        "\n",
        "class SRMConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, stride=1, padding=0):\n",
        "        super(SRMConv2d, self).__init__()\n",
        "        self.in_channels = 1\n",
        "        self.out_channels = 30\n",
        "        self.kernel_size = (5, 5)\n",
        "        if isinstance(stride, int):\n",
        "            self.stride = (stride, stride)\n",
        "        else:\n",
        "            self.stride = stride\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = (padding, padding)\n",
        "        else:\n",
        "            self.padding = padding\n",
        "        self.dilation = (1, 1)\n",
        "        self.transpose = False\n",
        "        self.output_padding = (0,)\n",
        "        self.groups = 1\n",
        "        self.weight = Parameter(torch.Tensor(30, 1, 5, 5), requires_grad=True)\n",
        "        self.bias = Parameter(torch.Tensor(30), requires_grad=True)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.numpy()[:] = SRM_npy\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.conv2d(input, self.weight, self.bias, self.stride, self.padding,\n",
        "                        self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class BlockA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None,activation = nn.ReLU(inplace=True)):\n",
        "        super(BlockA, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR-kU_0jj-fm"
      },
      "source": [
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    return (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymQw_QPj8M6"
      },
      "source": [
        "class BlockB(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockB, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes, stride=2)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "        # self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.shortcut_conv = conv1x1(in_planes, out_planes, stride=2)\n",
        "        self.shortcut_bn = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # out = self.pool(out)\n",
        "\n",
        "        identity = self.shortcut_conv(identity)\n",
        "        identity = self.shortcut_bn(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syGiDmSgkECX"
      },
      "source": [
        "class KeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer=None, zero_init_residual=True, p=0.5):\n",
        "        super(KeNet, self).__init__()\n",
        "\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.srm = SRMConv2d(1, 0)\n",
        "        self.bn1 = norm_layer(30)\n",
        "\n",
        "        self.A1 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.A2 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.AA = BlockA(30, 30, norm_layer=norm_layer)\n",
        "\n",
        "        # self.B1 = BlockB(30, 30, norm_layer=norm_layer)\n",
        "        # self.B2 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B3 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "        self.A3 = BlockA(64, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B4 = BlockB(64, 128, norm_layer=norm_layer)\n",
        "        self.A4 = BlockA(128, 128, norm_layer=norm_layer)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # self.bnfc = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # self.fcfusion = nn.Linear(128, 128) #4\n",
        "        self.fc = nn.Linear(128 * 4 + 1, 2)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.bias, 0.2)\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "        if self.zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, (BlockA, BlockB)):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        x = x.float()\n",
        "        out = self.srm(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.A1(out)\n",
        "        out = self.A2(out)\n",
        "        out = self.AA(out)\n",
        "\n",
        "        # out = self.B1(out)\n",
        "        # out = self.B2(out)\n",
        "\n",
        "        out = self.B3(out)\n",
        "        out = self.A3(out)\n",
        "\n",
        "        out = self.B4(out)\n",
        "        out = self.A4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), out.size(1))\n",
        "\n",
        "        # out = self.relu(out)\n",
        "        # out = self.bnfc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, *args):\n",
        "        ############# statistics fusion start #############\n",
        "        feats = torch.stack(\n",
        "            [self.extract_feat(subarea) for subarea in args], dim=0\n",
        "        )\n",
        "\n",
        "        euclidean_distance = F.pairwise_distance(feats[0], feats[1], eps=1e-6,\n",
        "                                                 keepdim=True)\n",
        "\n",
        "        if feats.shape[0] == 1:\n",
        "            final_feat = feats.squeeze(dim=0)\n",
        "        else:\n",
        "            # feats_sum = feats.sum(dim=0)\n",
        "            # feats_sub = feats[0] - feats[1]\n",
        "            feats_mean = feats.mean(dim=0)\n",
        "            feats_var = feats.var(dim=0)\n",
        "            feats_min, _ = feats.min(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)\n",
        "\n",
        "            '''feats_sum = feats.sum(dim=0)\n",
        "            feats_sub = abs(feats[0] - feats[1])\n",
        "            feats_prod = feats.prod(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)'''\n",
        "            \n",
        "            #final_feat = torch.cat(\n",
        "            #    [feats[0], feats[1], feats[0], feats[1]], dim=-1\n",
        "            #    #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            #)\n",
        "\n",
        "            final_feat = torch.cat(\n",
        "                [euclidean_distance, feats_mean, feats_var, feats_min, feats_max], dim=-1\n",
        "                #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            )\n",
        "\n",
        "        out = self.dropout(final_feat)\n",
        "        # out = self.fcfusion(out)\n",
        "        # out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, feats[0], feats[1]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75JIv1swkKYs"
      },
      "source": [
        "def preprocess_data(images, labels, random_crop, gpu):\n",
        "    # images of shape: NxCxHxW\n",
        "    if images.ndim == 5:  # 1xNxCxHxW\n",
        "        images = images.squeeze(0)\n",
        "        labels = labels.squeeze(0)\n",
        "    h, w = images.shape[-2:]\n",
        "\n",
        "    if random_crop:\n",
        "        ch = random.randint(h * 3 // 4, h)  # h // 2      #256\n",
        "        cw = random.randint(w * 3 // 4, w)  # square ch   #256\n",
        "\n",
        "        h0 = random.randint(0, h - ch)  # 128\n",
        "        w0 = random.randint(0, w - cw)  # 128\n",
        "    else:\n",
        "        ch, cw, h0, w0 = h, w, 0, 0\n",
        " \n",
        "    cw = cw & ~1\n",
        "    inputs = [\n",
        "                images[..., h0:h0 + ch, w0:w0 + cw // 2],\n",
        "                images[..., h0:h0 + ch, w0 + cw // 2:w0 + cw]\n",
        "        ]\n",
        "    if gpu:\n",
        "        inputs = [x.cuda() for x in inputs]\n",
        "        labels = labels.cuda()\n",
        "    return inputs, labels\n",
        "        \n",
        "    return inputs, labels"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbJpr35kP9x"
      },
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin=1.25):  # margin=2\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        label = label.to(torch.float32)\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWrAjBzGnulQ"
      },
      "source": [
        "model = KeNet(norm_layer=None, zero_init_residual=True, p=0.5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCfXKC1qkSx6"
      },
      "source": [
        "criterion_1 = nn.CrossEntropyLoss()\n",
        "criterion_2 = ContrastiveLoss(margin=1.25)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfLinZQImsQ5"
      },
      "source": [
        "# inputs , labels = preprocess_data(*data,False,gpu=True)\n",
        "# output, feat_0, feat_1 = model(*inputs)\n",
        "\n",
        "# print(output,feat_0,feat_1)\n",
        "# print(output.shape)\n",
        "# print(feat_0.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XVw46tVEgq"
      },
      "source": [
        "optimizer = Adamax(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9POVh9qM8YI"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.3,\n",
        "                                                           patience=10, verbose=True, min_lr=0,\n",
        "                                                           eps=1e-08)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_wn4oBeUbX"
      },
      "source": [
        "#  VALIDATION AND TRAINING STARTS #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8XNYMUvTWtj"
      },
      "source": [
        "def set_random_seed(seed=None):\n",
        "    \"\"\"Sets random seed for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = (\n",
        "                os.getpid()\n",
        "                + int(datetime.now().strftime(\"%S%f\"))\n",
        "                + int.from_bytes(os.urandom(2), \"big\")\n",
        "        )\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Using a generated random seed {}'.format(seed))\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.set_rng_state(torch.manual_seed(seed).get_state())\n",
        "\n",
        "\n",
        "def get_random_seed():\n",
        "    return np.random.randint(2 ** 31)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0HIDrzL5lU"
      },
      "source": [
        "import torchvision\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "\n",
        "\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Sampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TrainingSampler(Sampler):\n",
        "\n",
        "    def __init__(self, size, seed=None, shuffle=True):\n",
        "        self._size = size\n",
        "        self._shuffle = shuffle\n",
        "\n",
        "        if seed is None:\n",
        "            seed = get_random_seed()\n",
        "        self._seed = seed\n",
        "\n",
        "    def __iter__(self):\n",
        "        yield from itertools.islice(self._infinite_indices(), 0, None, 1)\n",
        "\n",
        "    def _infinite_indices(self):\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(self._seed)\n",
        "        while True:\n",
        "            if self._shuffle:\n",
        "                yield from torch.randperm(self._size, generator=g)\n",
        "            else:\n",
        "                yield from torch.arange(self._size)\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "\n",
        "    def __init__(self, sampler, group_ids, batch_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sampler (Sampler): Base sampler.\n",
        "            group_ids (list[int]): If the sampler produces indices in range [0, N),\n",
        "                `group_ids` must be a list of `N` ints which contains the group id of each\n",
        "                sample. The group ids must be a set of integers in [0, num_groups).\n",
        "            batch_size (int): Size of mini-batch.\n",
        "        \"\"\"\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of torch.utils.data.Sampler, \"\n",
        "                             \"but got sampler={}\".format(sampler))\n",
        "\n",
        "        self._sampler = sampler\n",
        "        self._group_ids = np.asarray(group_ids)\n",
        "        assert self._group_ids.ndim == 1\n",
        "        self._batch_size = batch_size\n",
        "        groups = np.unique(self._group_ids).tolist()\n",
        "        assert batch_size % len(groups) == 0\n",
        "\n",
        "        # buffer the indices of each group until batch size is reached\n",
        "        self._buffer_per_group = {k: [] for k in groups}\n",
        "        self._group_size = batch_size // len(groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in self._sampler:\n",
        "            group_id = self._group_ids[idx]\n",
        "            self._buffer_per_group[group_id].append(idx)\n",
        "            if all(len(v) >= self._group_size for k, v in self._buffer_per_group.items()):\n",
        "                idxs = []\n",
        "                # Collect across all groups\n",
        "                for k, v in self._buffer_per_group.items():\n",
        "                    idxs.extend(v[:self._group_size])\n",
        "                    del v[:self._group_size]\n",
        "\n",
        "                idxs = np.random.permutation(idxs)\n",
        "                yield idxs\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError(\"len() of GroupedBatchSampler is not well-defined.\")\n",
        "\n",
        "\n",
        "def build_train_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = transforms.Compose([\n",
        "        RandomRot(),\n",
        "        RandomFlip(),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "   # print(dataset.images)\n",
        "\n",
        "    size = len(dataset)\n",
        "\n",
        "    sampler = TrainingSampler(size)\n",
        "\n",
        "\n",
        "    batch_sampler = BalancedBatchSampler(sampler, dataset.labels, batch_size)\n",
        "    \n",
        "  # print(batch_sampler)\n",
        "    epoch_length = math.ceil(size / batch_size)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        worker_init_fn= worker_init_reset_seed(0)\n",
        "    )\n",
        "    return train_loader, epoch_length\n",
        "\n",
        "def worker_init_reset_seed(worker_id):\n",
        "    set_random_seed(np.random.randint(2 ** 31) + worker_id)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK-DnUZ0UoMU"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "class CoverStegoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, cover_dir, stego_dir, transform=None):\n",
        "        self._transform = transform\n",
        "\n",
        "        self.images, self.labels = self.get_items(cover_dir, stego_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.images[idx]))\n",
        "        image = np.expand_dims(image, 2)  # (H, W, C)\n",
        "        assert image.ndim == 3\n",
        "\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'label': self.labels[idx]\n",
        "        }\n",
        "\n",
        "        if self._transform:\n",
        "            sample = self._transform(sample)\n",
        "        return sample\n",
        "\n",
        "    @staticmethod\n",
        "    def get_items(cover_dir, stego_dir):\n",
        "        images, labels = [], []\n",
        "\n",
        "        cover_names = sorted(os.listdir(cover_dir))\n",
        "        if stego_dir is not None:\n",
        "            stego_names = sorted(os.listdir(stego_dir))\n",
        "            assert cover_names == stego_names\n",
        "\n",
        "        file_names = cover_names\n",
        "        if stego_dir is None:\n",
        "            dir_to_label = [(cover_dir, 0), ]\n",
        "        else:\n",
        "            dir_to_label = [(cover_dir, 0), (stego_dir, 1)]\n",
        "        for image_dir, label in dir_to_label:\n",
        "            for file_name in file_names:\n",
        "                image_path = os.path.join(image_dir, file_name)\n",
        "                if not os.path.isfile(image_path):\n",
        "                    raise FileNotFoundError('{} not exists'.format(image_path))\n",
        "                images.append(image_path)\n",
        "                labels.append(label)\n",
        "\n",
        "        return images, labels"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7xayQfnPoxb"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "\n",
        "class RandomRot(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        rot = random.randint(0, 3)\n",
        "        return {\n",
        "            'image': np.rot90(sample['image'], rot, axes=[-3, -2]).copy(),\n",
        "            'label': sample['label'],\n",
        "        }\n",
        "\n",
        "\n",
        "class RandomFlip(object):\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self._p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if random.random() < self._p:\n",
        "            return {\n",
        "                'image': np.flip(sample['image'], axis=-2).copy(),\n",
        "                'label': sample['label'],\n",
        "            }\n",
        "        else:\n",
        "            return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if image.ndim == 3:  # HxWxC\n",
        "            image = image.transpose(2, 0, 1)\n",
        "        else:  # NxHxWxC\n",
        "            image = image.transpose(0, 3, 1, 2)\n",
        "        return {\n",
        "            'image': torch.from_numpy(image).type(torch.FloatTensor),\n",
        "            'label': torch.tensor(label).long()\n",
        "        }\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml7PWEMFP0b4"
      },
      "source": [
        "covr_dir = \"/content/drive/MyDrive/boss_256/train/cover\"\n",
        "steg_dir = \"/content/drive/MyDrive/boss_256/train/stego\"\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsZc7hMUwrN8"
      },
      "source": [
        "# print(sorted(os.listdir(covr_dir)),\"==================\\n\",sorted(os.listdir(steg_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-h1TIR-Vgas"
      },
      "source": [
        "seed = 10\n",
        "set_random_seed(None if seed < 0 else seed)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ukSmf-VLdP"
      },
      "source": [
        "train_loader, epoch_length = build_train_loader(\n",
        "        covr_dir, steg_dir, batch_size=32,\n",
        "        num_workers = 0\n",
        "    )"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4XE95M1Wwiq"
      },
      "source": [
        "train_loader_iter = iter(train_loader)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OhGiwv3I6Tc"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah9WzsnbJ-37",
        "outputId": "49198a8c-e0f2-4b33-d644-193b9ccaa4f8"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLjGIZhrRjgT"
      },
      "source": [
        "if device.type == \"cuda\":\n",
        "  model.cuda()\n",
        "  criterion_1.cuda()\n",
        "  criterion_2.cuda()\n",
        "\n",
        "log_interval = 10"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cKIz_vxXHvz"
      },
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  running_loss, running_accuracy = 0., 0.\n",
        "  for batch in range(epoch):\n",
        "    data = next(iter(train_loader_iter))\n",
        "    img, lab = data[\"image\"], data[\"label\"]\n",
        "    inputs , labels = preprocess_data(img, lab, False,gpu= True)\n",
        "    optimizer.zero_grad()\n",
        "    output, feat_0, feat_1 = model(*inputs)\n",
        "    loss = criterion_1(output, labels) + 0.1 * criterion_2(feat_0, feat_1, labels)\n",
        "\n",
        "\n",
        "    the_accuracy = accuracy(output, labels).item()\n",
        "  #  running_accuracy += the_accuracy\n",
        "  #  running_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print('EPOCH :',batch,\"LOSS:\", loss.item(),'the_accuracy :',the_accuracy,'\\n')\n",
        "    model.train()\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gGd0KcAXUq6"
      },
      "source": [
        "def validate(epoch):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for d in range(epoch):\n",
        "      data = next(iter(train_loader_iter))\n",
        "      image, lab = data[\"image\"], data[\"label\"]\n",
        "      i, l = preprocess_data(image, lab,False,gpu = True)\n",
        "      if epoch == 1:\n",
        "        print(lab)\n",
        "      output, feat0, feat1 = model(*i)\n",
        "      for idx, j in enumerate(output):\n",
        "        print(torch.argmax(j),\"--\",lab[idx])\n",
        "        if torch.argmax(j) == lab[idx]:\n",
        "          correct += 1\n",
        "        total +=1\n",
        "  \n",
        "  print(\"ACCURACY :\", correct/total,\"total :\",total, \"correct :\",correct )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fszWpUzio3H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "d414c0ba-e8d5-41c1-d438-83c6bb3e46e7"
      },
      "source": [
        "train(100)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH : 0 LOSS: 0.7342522740364075 the_accuracy : 0.5625 \n",
            "\n",
            "EPOCH : 1 LOSS: 0.7347314357757568 the_accuracy : 0.625 \n",
            "\n",
            "EPOCH : 2 LOSS: 0.7318613529205322 the_accuracy : 0.6875 \n",
            "\n",
            "EPOCH : 3 LOSS: 0.7418716549873352 the_accuracy : 0.5 \n",
            "\n",
            "EPOCH : 4 LOSS: 0.7419950366020203 the_accuracy : 0.40625 \n",
            "\n",
            "EPOCH : 5 LOSS: 0.7415194511413574 the_accuracy : 0.53125 \n",
            "\n",
            "EPOCH : 6 LOSS: 0.7280482649803162 the_accuracy : 0.59375 \n",
            "\n",
            "EPOCH : 7 LOSS: 0.7380422353744507 the_accuracy : 0.5 \n",
            "\n",
            "EPOCH : 8 LOSS: 0.7433702349662781 the_accuracy : 0.375 \n",
            "\n",
            "EPOCH : 9 LOSS: 0.7567225694656372 the_accuracy : 0.375 \n",
            "\n",
            "EPOCH : 10 LOSS: 0.7391961216926575 the_accuracy : 0.5 \n",
            "\n",
            "EPOCH : 11 LOSS: 0.7603921294212341 the_accuracy : 0.3125 \n",
            "\n",
            "EPOCH : 12 LOSS: 0.7360002994537354 the_accuracy : 0.5625 \n",
            "\n",
            "EPOCH : 13 LOSS: 0.7493507266044617 the_accuracy : 0.46875 \n",
            "\n",
            "EPOCH : 14 LOSS: 0.7467511296272278 the_accuracy : 0.5625 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-51afd2885487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-39b11a2e5b91>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-a06354e5b3b2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (H, W, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGvtv_4w6wOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14837fc-e1d3-46a2-a3b2-bb644d8ef6ee"
      },
      "source": [
        "validate(2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(0)\n",
            "tensor(1, device='cuda:0') -- tensor(1)\n",
            "tensor(0, device='cuda:0') -- tensor(1)\n",
            "tensor(1, device='cuda:0') -- tensor(0)\n",
            "ACCURACY : 0.5625 total : 64 correct : 36\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}