{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_steagnalysis_SiaNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKUeYxMZJHJGnxELKH9czi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinraj9895/steganalysis/blob/main/Image_steagnalysis_SiaNET_Base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7dv2INO5zEY",
        "outputId": "04136399-6b79-4711-a3db-bbe53b8f2a93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqaWulTIOq5P"
      },
      "source": [
        "from datetime import datetime\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "def set_random_seed(seed=None):\n",
        "    \"\"\"Sets random seed for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = (\n",
        "                os.getpid()\n",
        "                + int(datetime.now().strftime(\"%S%f\"))\n",
        "                + int.from_bytes(os.urandom(2), \"big\")\n",
        "        )\n",
        "        logger = logging.getLogger(__name__)\n",
        "        logger.info('Using a generated random seed {}'.format(seed))\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.set_rng_state(torch.manual_seed(seed).get_state())\n",
        "\n",
        "\n",
        "def get_random_seed():\n",
        "    return np.random.randint(2 ** 31)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "175OQ-IlQ9RG"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class RandomRot(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        rot = random.randint(0, 3)\n",
        "        return {\n",
        "            'image': np.rot90(sample['image'], rot, axes=[-3, -2]).copy(),\n",
        "            'label': sample['label'],\n",
        "        }\n",
        "\n",
        "\n",
        "class RandomFlip(object):\n",
        "\n",
        "    def __init__(self, p=0.5):\n",
        "        self._p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if random.random() < self._p:\n",
        "            return {\n",
        "                'image': np.flip(sample['image'], axis=-2).copy(),\n",
        "                'label': sample['label'],\n",
        "            }\n",
        "        else:\n",
        "            return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample['image'], sample['label']\n",
        "        if image.ndim == 3:  # HxWxC\n",
        "            image = image.transpose(2, 0, 1)\n",
        "        else:  # NxHxWxC\n",
        "            image = image.transpose(0, 3, 1, 2)\n",
        "        return {\n",
        "            'image': torch.from_numpy(image).type(torch.FloatTensor),\n",
        "            'label': torch.tensor(label).long()\n",
        "        }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZxEAYoPQrcI"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CoverStegoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, cover_dir, stego_dir, transform=None):\n",
        "        self._transform = transform\n",
        "\n",
        "        self.images, self.labels = self.get_items(cover_dir, stego_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.images[idx]))\n",
        "        image = np.expand_dims(image, 2)  # (H, W, C)\n",
        "        assert image.ndim == 3\n",
        "\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'label': self.labels[idx]\n",
        "        }\n",
        "\n",
        "        if self._transform:\n",
        "            sample = self._transform(sample)\n",
        "        return sample\n",
        "\n",
        "    @staticmethod\n",
        "    def get_items(cover_dir, stego_dir):\n",
        "        images, labels = [], []\n",
        "\n",
        "        cover_names = sorted(os.listdir(cover_dir))\n",
        "        if stego_dir is not None:\n",
        "            stego_names = sorted(os.listdir(stego_dir))\n",
        "            assert cover_names == stego_names\n",
        "\n",
        "        file_names = cover_names\n",
        "        if stego_dir is None:\n",
        "            dir_to_label = [(cover_dir, 0), ]\n",
        "        else:\n",
        "            dir_to_label = [(cover_dir, 0), (stego_dir, 1)]\n",
        "        for image_dir, label in dir_to_label:\n",
        "            for file_name in file_names:\n",
        "                image_path = osp.join(image_dir, file_name)\n",
        "                if not osp.isfile(image_path):\n",
        "                    raise FileNotFoundError('{} not exists'.format(image_path))\n",
        "                images.append(image_path)\n",
        "                labels.append(label)\n",
        "\n",
        "        return images, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91278fr58-s"
      },
      "source": [
        "import torchvision\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Sampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "import itertools\n",
        "import logging\n",
        "import math\n",
        "\n",
        "class TrainingSampler(Sampler):\n",
        "\n",
        "    def __init__(self, size, seed=None, shuffle=True):\n",
        "        self._size = size\n",
        "        self._shuffle = shuffle\n",
        "\n",
        "        if seed is None:\n",
        "            seed = get_random_seed()\n",
        "        self._seed = seed\n",
        "\n",
        "    def __iter__(self):\n",
        "        yield from itertools.islice(self._infinite_indices(), 0, None, 1)\n",
        "\n",
        "    def _infinite_indices(self):\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(self._seed)\n",
        "        while True:\n",
        "            if self._shuffle:\n",
        "                yield from torch.randperm(self._size, generator=g)\n",
        "            else:\n",
        "                yield from torch.arange(self._size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "\n",
        "    def __init__(self, sampler, group_ids, batch_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sampler (Sampler): Base sampler.\n",
        "            group_ids (list[int]): If the sampler produces indices in range [0, N),\n",
        "                `group_ids` must be a list of `N` ints which contains the group id of each\n",
        "                sample. The group ids must be a set of integers in [0, num_groups).\n",
        "            batch_size (int): Size of mini-batch.\n",
        "        \"\"\"\n",
        "        if not isinstance(sampler, Sampler):\n",
        "            raise ValueError(\"sampler should be an instance of torch.utils.data.Sampler, \"\n",
        "                             \"but got sampler={}\".format(sampler))\n",
        "\n",
        "        self._sampler = sampler\n",
        "        self._group_ids = np.asarray(group_ids)\n",
        "        assert self._group_ids.ndim == 1\n",
        "        self._batch_size = batch_size\n",
        "        groups = np.unique(self._group_ids).tolist()\n",
        "        assert batch_size % len(groups) == 0\n",
        "\n",
        "        # buffer the indices of each group until batch size is reached\n",
        "        self._buffer_per_group = {k: [] for k in groups}\n",
        "        self._group_size = batch_size // len(groups)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for idx in self._sampler:\n",
        "            group_id = self._group_ids[idx]\n",
        "            self._buffer_per_group[group_id].append(idx)\n",
        "            if all(len(v) >= self._group_size for k, v in self._buffer_per_group.items()):\n",
        "                idxs = []\n",
        "                # Collect across all groups\n",
        "                for k, v in self._buffer_per_group.items():\n",
        "                    idxs.extend(v[:self._group_size])\n",
        "                    del v[:self._group_size]\n",
        "\n",
        "                idxs = np.random.permutation(idxs)\n",
        "                yield idxs\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError(\"len() of GroupedBatchSampler is not well-defined.\")\n",
        "\n",
        "\n",
        "def build_train_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        RandomRot(),\n",
        "        RandomFlip(),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "    size = len(dataset)\n",
        "    sampler = TrainingSampler(size)\n",
        "    if stego_dir is not None:\n",
        "        batch_sampler = BalancedBatchSampler(sampler, dataset.labels, batch_size)\n",
        "    else:\n",
        "        batch_sampler = BatchSampler(sampler, batch_size, drop_last=False)\n",
        "    epoch_length = math.ceil(size / batch_size)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        worker_init_fn=worker_init_reset_seed,\n",
        "    )\n",
        "    return train_loader, epoch_length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_val_loader(cover_dir, stego_dir, batch_size=32, num_workers=0):\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        ToTensor(),\n",
        "    ])\n",
        "    dataset = CoverStegoDataset(cover_dir, stego_dir, transform)\n",
        "\n",
        "    sampler = SequentialSampler(dataset)\n",
        "    batch_sampler = BatchSampler(sampler, batch_size, drop_last=False)\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "    )\n",
        "    return test_loader\n",
        "\n",
        "def worker_init_reset_seed(worker_id):\n",
        "    set_random_seed(np.random.randint(2 ** 31) + worker_id)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz1SmXalPkzz"
      },
      "source": [
        "set_random_seed()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdGRqGq_P7NN"
      },
      "source": [
        " train_cover_dir = \"/content/drive/MyDrive/boss_256/256_cropped_train/cover\"\n",
        " train_stego_dir = \"/content/drive/MyDrive/boss_256/256_cropped_train/stego\"\n",
        " val_cover_dir = \"/content/drive/MyDrive/boss_256/train/cover\"\n",
        " val_stego_dir = \"/content/drive/MyDrive/boss_256/train/stego\"\n",
        " \n",
        " \n",
        " train_loader, epoch_length = build_train_loader(\n",
        "        val_cover_dir, val_stego_dir, batch_size=32,\n",
        "        num_workers=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1c-rr7UsJqR"
      },
      "source": [
        "val_loader = build_val_loader(\n",
        "    train_cover_dir, train_stego_dir, batch_size=32,\n",
        "    num_workers=0\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgLZk_7xavka"
      },
      "source": [
        "train_loader_iter = iter(train_loader)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mCyjXydT3yp"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import Parameter\n",
        "\n",
        "\n",
        "srm_dir = \"/content/drive/MyDrive\"\n",
        "SRM_npy = np.load(os.path.join(srm_dir,\"SRM_Kernels.npy\"))\n",
        "\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    return (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class SRMConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, stride=1, padding=0):\n",
        "        super(SRMConv2d, self).__init__()\n",
        "        self.in_channels = 1\n",
        "        self.out_channels = 30\n",
        "        self.kernel_size = (5, 5)\n",
        "        if isinstance(stride, int):\n",
        "            self.stride = (stride, stride)\n",
        "        else:\n",
        "            self.stride = stride\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = (padding, padding)\n",
        "        else:\n",
        "            self.padding = padding\n",
        "        self.dilation = (1, 1)\n",
        "        self.transpose = False\n",
        "        self.output_padding = (0,)\n",
        "        self.groups = 1\n",
        "        self.weight = Parameter(torch.Tensor(30, 1, 5, 5), requires_grad=True)\n",
        "        self.bias = Parameter(torch.Tensor(30), requires_grad=True)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.numpy()[:] = SRM_npy\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.conv2d(input, self.weight, self.bias, self.stride, self.padding,\n",
        "                        self.dilation, self.groups)\n",
        "\n",
        "\n",
        "class BlockA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockA, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class BlockB(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, norm_layer=None):\n",
        "        super(BlockB, self).__init__()\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.conv1 = conv3x3(in_planes, out_planes, stride=2)\n",
        "        self.bn1 = norm_layer(out_planes)\n",
        "        self.conv2 = conv3x3(out_planes, out_planes)\n",
        "        self.bn2 = norm_layer(out_planes)\n",
        "        # self.pool = nn.AvgPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.shortcut_conv = conv1x1(in_planes, out_planes, stride=2)\n",
        "        self.shortcut_bn = norm_layer(out_planes)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        # out = self.pool(out)\n",
        "\n",
        "        identity = self.shortcut_conv(identity)\n",
        "        identity = self.shortcut_bn(identity)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbvp0KdThp7"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class KeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, norm_layer=None, zero_init_residual=True, p=0.5):\n",
        "        super(KeNet, self).__init__()\n",
        "\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.srm = SRMConv2d(1, 0)\n",
        "        self.bn1 = norm_layer(30)\n",
        "\n",
        "        self.A1 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.A2 = BlockA(30, 30, norm_layer=norm_layer)\n",
        "        self.AA = BlockA(30, 30, norm_layer=norm_layer)\n",
        "\n",
        "        # self.B1 = BlockB(30, 30, norm_layer=norm_layer)\n",
        "        # self.B2 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B3 = BlockB(30, 64, norm_layer=norm_layer)\n",
        "        self.A3 = BlockA(64, 64, norm_layer=norm_layer)\n",
        "\n",
        "        self.B4 = BlockB(64, 128, norm_layer=norm_layer)\n",
        "        self.A4 = BlockA(128, 128, norm_layer=norm_layer)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # self.bnfc = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # self.fcfusion = nn.Linear(128, 128) #4\n",
        "        self.fc = nn.Linear(128 * 4 + 1, 2)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.bias, 0.2)\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "        if self.zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, (BlockA, BlockB)):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def extract_feat(self, x):\n",
        "        x = x.float()\n",
        "        out = self.srm(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.A1(out)\n",
        "        out = self.A2(out)\n",
        "        out = self.AA(out)\n",
        "\n",
        "        # out = self.B1(out)\n",
        "        # out = self.B2(out)\n",
        "\n",
        "        out = self.B3(out)\n",
        "        out = self.A3(out)\n",
        "\n",
        "        out = self.B4(out)\n",
        "        out = self.A4(out)\n",
        "\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), out.size(1))\n",
        "\n",
        "        # out = self.relu(out)\n",
        "        # out = self.bnfc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, *args):\n",
        "        ############# statistics fusion start #############\n",
        "        feats = torch.stack(\n",
        "            [self.extract_feat(subarea) for subarea in args], dim=0\n",
        "        )\n",
        "\n",
        "        euclidean_distance = F.pairwise_distance(feats[0], feats[1], eps=1e-6,\n",
        "                                                 keepdim=True)\n",
        "\n",
        "        if feats.shape[0] == 1:\n",
        "            final_feat = feats.squeeze(dim=0)\n",
        "        else:\n",
        "            # feats_sum = feats.sum(dim=0)\n",
        "            # feats_sub = feats[0] - feats[1]\n",
        "            feats_mean = feats.mean(dim=0)\n",
        "            feats_var = feats.var(dim=0)\n",
        "            feats_min, _ = feats.min(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)\n",
        "\n",
        "            '''feats_sum = feats.sum(dim=0)\n",
        "            feats_sub = abs(feats[0] - feats[1])\n",
        "            feats_prod = feats.prod(dim=0)\n",
        "            feats_max, _ = feats.max(dim=0)'''\n",
        "            \n",
        "            #final_feat = torch.cat(\n",
        "            #    [feats[0], feats[1], feats[0], feats[1]], dim=-1\n",
        "            #    #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            #)\n",
        "\n",
        "            final_feat = torch.cat(\n",
        "                [euclidean_distance, feats_mean, feats_var, feats_min, feats_max], dim=-1\n",
        "                #[euclidean_distance, feats_sum, feats_sub, feats_prod, feats_max], dim=-1\n",
        "            )\n",
        "\n",
        "        out = self.dropout(final_feat)\n",
        "        # out = self.fcfusion(out)\n",
        "        # out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, feats[0], feats[1]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzhXzdCFWHh8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin=1.25):  # margin=2\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        label = label.to(torch.float32)\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        )\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3VifExXUbMj"
      },
      "source": [
        "criterion_1 = nn.CrossEntropyLoss()\n",
        "criterion_2 = ContrastiveLoss(margin=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty1kf2kGYmgT"
      },
      "source": [
        "net = KeNet();"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTokfBpUXydL"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    net.cuda()\n",
        "    criterion_1.cuda()\n",
        "    criterion_2.cuda()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2W6WHALZB8H"
      },
      "source": [
        "from torch.optim.adamax import Adamax\n",
        "\n",
        "optimizer = Adamax(net.parameters(), lr=0.001, eps=1e-08, weight_decay=0.0001)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvtWoO5xqMMV"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.3,\n",
        "                                                           patience=10, verbose=True, min_lr=0,\n",
        "                                                           eps=1e-08)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTdhQ_wXZ177"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "import shutil\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def preprocess_data(images, labels, random_crop,gpu):\n",
        "    # images of shape: NxCxHxW\n",
        "    if images.ndim == 5:  # 1xNxCxHxW\n",
        "        images = images.squeeze(0)\n",
        "        labels = labels.squeeze(0)\n",
        "    h, w = images.shape[-2:]\n",
        "\n",
        "    if random_crop:\n",
        "        ch = random.randint(h * 3 // 4, h)  # h // 2      #256\n",
        "        cw = random.randint(w * 3 // 4, w)  # square ch   #256\n",
        "\n",
        "        h0 = random.randint(0, h - ch)  # 128\n",
        "        w0 = random.randint(0, w - cw)  # 128\n",
        "    else:\n",
        "        ch, cw, h0, w0 = h, w, 0, 0\n",
        "\n",
        "\n",
        "    cw = cw & ~1\n",
        "    inputs = [\n",
        "            images[..., h0:h0 + ch, w0:w0 + cw // 2],\n",
        "            images[..., h0:h0 + ch, w0 + cw // 2:w0 + cw]\n",
        "        ]\n",
        "\n",
        "    if gpu:\n",
        "        inputs = [x.cuda() for x in inputs]\n",
        "        labels = labels.cuda()\n",
        "    return inputs, labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMPL0h7NaYje"
      },
      "source": [
        "def train(epoch):\n",
        "    net.train()\n",
        "    running_loss, running_accuracy = 0., 0.\n",
        "\n",
        "    for batch_idx in range(epoch_length):\n",
        "        data = next(train_loader_iter)\n",
        "        inputs, labels = preprocess_data(data['image'], data['label'], False,gpu=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "   \n",
        "        outputs, feats_0, feats_1 = net(*inputs)\n",
        "\n",
        "            # count parameters start\n",
        "            # print('parameters_count: {}'.format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
        "            # count parameters end\n",
        "\n",
        "        loss = criterion_1(outputs, labels) + \\\n",
        "                   0.1 * criterion_2(feats_0, feats_1, labels)\n",
        "\n",
        "        accuracy1 = accuracy(outputs, labels).item()\n",
        "        running_accuracy += accuracy1\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            running_accuracy /= 10\n",
        "            running_loss /= 10\n",
        "            \n",
        "            print(\n",
        "                'Train epoch: {} [{}/{}]\\tAccuracy: {:.2f}%\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx + 1, epoch_length, 100 * running_accuracy,\n",
        "                    running_loss))\n",
        "                    \n",
        "            ###############################log per log_interval start\n",
        "            is_best=False\n",
        "            save_checkpoint(\n",
        "                {\n",
        "                    'iteration': batch_idx + 1,\n",
        "                    'state_dict': net.state_dict(),\n",
        "                    'best_prec1': running_accuracy,\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                },\n",
        "                is_best,\n",
        "                filename=os.path.join(\"/content/drive/MyDrive/dataset\", 'checkpoint.pth.tar'),\n",
        "                best_name=os.path.join(\"/content/drive/MyDrive/dataset\", 'model_best.pth.tar'))\n",
        "            ###############################\n",
        "            running_loss = 0.\n",
        "            running_accuracy = 0.\n",
        "            net.train()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYQb3yVrVCL"
      },
      "source": [
        "def valid():\n",
        "    net.eval()\n",
        "    valid_loss = 0.\n",
        "    valid_accuracy = 0.\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            inputs, labels = preprocess_data(data['image'], data['label'], False,gpu = True)\n",
        "\n",
        "            outputs, feats_0, feats_1 = net(*inputs)\n",
        "            valid_loss += criterion_1(outputs, labels).item() + \\\n",
        "                              0.01 * criterion_2(feats_0, feats_1, labels)\n",
        "            valid_accuracy += accuracy(outputs, labels).item()\n",
        "    valid_loss /= len(val_loader)\n",
        "    valid_accuracy /= len(val_loader)\n",
        "    print('Test set: Loss: {:.4f}, Accuracy: {:.2f}%)'.format(\n",
        "        valid_loss, 100 * valid_accuracy))\n",
        "    return valid_loss, valid_accuracy\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtT-ktcdb_k4"
      },
      "source": [
        "fine_tune = \"/content/drive/MyDrive/dataset/checkpoint.pth.tar\"\n",
        "\n",
        "if fine_tune is not None:\n",
        "    net.load_state_dict(torch.load(fine_tune)['state_dict'], strict=False)\n",
        "    e = torch.load(fine_tune)['iteration']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Z0YRe2dMOK",
        "outputId": "785033f0-df6a-43ec-c8ed-220d77d3e90a"
      },
      "source": [
        "print(e)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAaeRXveb85B",
        "outputId": "b78582b5-9bdd-4a4c-c8e9-f61856832164"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename, best_name):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, best_name)\n",
        "\n",
        "\n",
        "_time = time.time()\n",
        "best_accuracy = 0.\n",
        "for e in range(1, 500 + 1):\n",
        "    logger.info('Epoch: {}'.format(e))\n",
        "    logger.info('Train')\n",
        "    train(e)\n",
        "    logger.info('Time: {}'.format(time.time() - _time))\n",
        "    logger.info('Test')\n",
        "    _, accuracy1 = valid()\n",
        "    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "        scheduler.step(accuracy1)\n",
        "    else:\n",
        "        scheduler.step()\n",
        "    if accuracy1 > best_accuracy:\n",
        "        best_accuracy = accuracy1\n",
        "        is_best = True\n",
        "    else:\n",
        "        is_best = False\n",
        "    logger.info('Best accuracy: {}'.format(best_accuracy))\n",
        "    logger.info('Time: {}'.format(time.time() - _time))\n",
        "    save_checkpoint(\n",
        "        {\n",
        "            'epoch': e,\n",
        "            'state_dict': net.state_dict(),\n",
        "            'best_prec1': accuracy1,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        },\n",
        "        is_best,\n",
        "        filename=os.path.join(\"/content/drive/MyDrive/dataset\", 'checkpoint.pth.tar'),\n",
        "        best_name=os.path.join(\"/content/drive/MyDrive/dataset\", 'model_best.pth.tar'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch: 1 [10/625]\tAccuracy: 81.25%\tLoss: 0.409857\n",
            "Train epoch: 1 [20/625]\tAccuracy: 83.75%\tLoss: 0.374335\n",
            "Train epoch: 1 [30/625]\tAccuracy: 83.75%\tLoss: 0.341373\n",
            "Train epoch: 1 [40/625]\tAccuracy: 85.62%\tLoss: 0.288514\n",
            "Train epoch: 1 [50/625]\tAccuracy: 87.50%\tLoss: 0.268404\n",
            "Train epoch: 1 [60/625]\tAccuracy: 90.62%\tLoss: 0.258045\n",
            "Train epoch: 1 [70/625]\tAccuracy: 84.06%\tLoss: 0.354046\n",
            "Train epoch: 1 [80/625]\tAccuracy: 84.69%\tLoss: 0.324663\n",
            "Train epoch: 1 [90/625]\tAccuracy: 84.38%\tLoss: 0.320991\n",
            "Train epoch: 1 [100/625]\tAccuracy: 86.88%\tLoss: 0.269839\n",
            "Train epoch: 1 [110/625]\tAccuracy: 87.81%\tLoss: 0.282748\n",
            "Train epoch: 1 [120/625]\tAccuracy: 86.25%\tLoss: 0.348060\n",
            "Train epoch: 1 [130/625]\tAccuracy: 87.19%\tLoss: 0.270929\n",
            "Train epoch: 1 [140/625]\tAccuracy: 87.50%\tLoss: 0.296366\n",
            "Train epoch: 1 [150/625]\tAccuracy: 89.06%\tLoss: 0.267682\n",
            "Train epoch: 1 [160/625]\tAccuracy: 87.50%\tLoss: 0.264580\n",
            "Train epoch: 1 [170/625]\tAccuracy: 87.81%\tLoss: 0.310484\n",
            "Train epoch: 1 [180/625]\tAccuracy: 90.31%\tLoss: 0.269371\n",
            "Train epoch: 1 [190/625]\tAccuracy: 85.00%\tLoss: 0.343598\n",
            "Train epoch: 1 [200/625]\tAccuracy: 87.81%\tLoss: 0.308616\n",
            "Train epoch: 1 [210/625]\tAccuracy: 85.94%\tLoss: 0.301153\n",
            "Train epoch: 1 [220/625]\tAccuracy: 90.94%\tLoss: 0.235077\n",
            "Train epoch: 1 [230/625]\tAccuracy: 90.31%\tLoss: 0.242791\n",
            "Train epoch: 1 [240/625]\tAccuracy: 86.25%\tLoss: 0.312805\n",
            "Train epoch: 1 [250/625]\tAccuracy: 83.75%\tLoss: 0.369784\n",
            "Train epoch: 1 [260/625]\tAccuracy: 92.50%\tLoss: 0.231642\n",
            "Train epoch: 1 [270/625]\tAccuracy: 87.50%\tLoss: 0.264323\n",
            "Train epoch: 1 [280/625]\tAccuracy: 89.69%\tLoss: 0.249149\n",
            "Train epoch: 1 [290/625]\tAccuracy: 83.12%\tLoss: 0.311537\n",
            "Train epoch: 1 [300/625]\tAccuracy: 90.31%\tLoss: 0.237744\n",
            "Train epoch: 1 [310/625]\tAccuracy: 88.12%\tLoss: 0.263269\n",
            "Train epoch: 1 [320/625]\tAccuracy: 87.81%\tLoss: 0.294071\n",
            "Train epoch: 1 [330/625]\tAccuracy: 87.81%\tLoss: 0.266497\n",
            "Train epoch: 1 [340/625]\tAccuracy: 89.69%\tLoss: 0.280149\n",
            "Train epoch: 1 [350/625]\tAccuracy: 86.25%\tLoss: 0.305129\n",
            "Train epoch: 1 [360/625]\tAccuracy: 87.81%\tLoss: 0.293259\n",
            "Train epoch: 1 [370/625]\tAccuracy: 91.88%\tLoss: 0.243917\n",
            "Train epoch: 1 [380/625]\tAccuracy: 86.88%\tLoss: 0.266874\n",
            "Train epoch: 1 [390/625]\tAccuracy: 89.69%\tLoss: 0.254529\n",
            "Train epoch: 1 [400/625]\tAccuracy: 86.56%\tLoss: 0.294468\n",
            "Train epoch: 1 [410/625]\tAccuracy: 88.44%\tLoss: 0.270052\n",
            "Train epoch: 1 [420/625]\tAccuracy: 89.06%\tLoss: 0.243566\n",
            "Train epoch: 1 [430/625]\tAccuracy: 88.75%\tLoss: 0.265544\n",
            "Train epoch: 1 [440/625]\tAccuracy: 84.38%\tLoss: 0.306176\n",
            "Train epoch: 1 [450/625]\tAccuracy: 85.94%\tLoss: 0.293939\n",
            "Train epoch: 1 [460/625]\tAccuracy: 85.94%\tLoss: 0.311838\n",
            "Train epoch: 1 [470/625]\tAccuracy: 88.12%\tLoss: 0.249665\n",
            "Train epoch: 1 [480/625]\tAccuracy: 90.94%\tLoss: 0.242692\n",
            "Train epoch: 1 [490/625]\tAccuracy: 87.19%\tLoss: 0.267679\n",
            "Train epoch: 1 [500/625]\tAccuracy: 85.00%\tLoss: 0.331119\n",
            "Train epoch: 1 [510/625]\tAccuracy: 89.69%\tLoss: 0.245970\n",
            "Train epoch: 1 [520/625]\tAccuracy: 88.12%\tLoss: 0.283546\n",
            "Train epoch: 1 [530/625]\tAccuracy: 91.88%\tLoss: 0.259310\n",
            "Train epoch: 1 [540/625]\tAccuracy: 84.38%\tLoss: 0.307580\n",
            "Train epoch: 1 [550/625]\tAccuracy: 85.62%\tLoss: 0.259656\n",
            "Train epoch: 1 [560/625]\tAccuracy: 89.38%\tLoss: 0.258958\n",
            "Train epoch: 1 [570/625]\tAccuracy: 88.44%\tLoss: 0.260468\n",
            "Train epoch: 1 [580/625]\tAccuracy: 85.62%\tLoss: 0.296196\n",
            "Train epoch: 1 [590/625]\tAccuracy: 85.94%\tLoss: 0.358589\n",
            "Train epoch: 1 [600/625]\tAccuracy: 86.56%\tLoss: 0.269666\n",
            "Train epoch: 1 [610/625]\tAccuracy: 90.00%\tLoss: 0.252745\n",
            "Train epoch: 1 [620/625]\tAccuracy: 87.19%\tLoss: 0.280172\n",
            "Test set: Loss: 0.6156, Accuracy: 66.56%)\n",
            "Train epoch: 2 [10/625]\tAccuracy: 92.19%\tLoss: 0.212418\n",
            "Train epoch: 2 [20/625]\tAccuracy: 86.56%\tLoss: 0.307297\n",
            "Train epoch: 2 [30/625]\tAccuracy: 88.12%\tLoss: 0.263796\n",
            "Train epoch: 2 [40/625]\tAccuracy: 86.88%\tLoss: 0.298058\n",
            "Train epoch: 2 [50/625]\tAccuracy: 90.94%\tLoss: 0.240867\n",
            "Train epoch: 2 [60/625]\tAccuracy: 84.38%\tLoss: 0.304680\n",
            "Train epoch: 2 [70/625]\tAccuracy: 88.75%\tLoss: 0.264308\n",
            "Train epoch: 2 [80/625]\tAccuracy: 85.94%\tLoss: 0.325256\n",
            "Train epoch: 2 [90/625]\tAccuracy: 89.38%\tLoss: 0.256639\n",
            "Train epoch: 2 [100/625]\tAccuracy: 88.75%\tLoss: 0.274542\n",
            "Train epoch: 2 [110/625]\tAccuracy: 89.38%\tLoss: 0.258549\n",
            "Train epoch: 2 [120/625]\tAccuracy: 87.81%\tLoss: 0.265902\n",
            "Train epoch: 2 [130/625]\tAccuracy: 87.19%\tLoss: 0.296778\n",
            "Train epoch: 2 [140/625]\tAccuracy: 87.81%\tLoss: 0.264248\n",
            "Train epoch: 2 [150/625]\tAccuracy: 88.44%\tLoss: 0.274656\n",
            "Train epoch: 2 [160/625]\tAccuracy: 89.38%\tLoss: 0.267201\n",
            "Train epoch: 2 [170/625]\tAccuracy: 87.50%\tLoss: 0.297509\n",
            "Train epoch: 2 [180/625]\tAccuracy: 89.69%\tLoss: 0.268931\n",
            "Train epoch: 2 [190/625]\tAccuracy: 90.62%\tLoss: 0.256985\n",
            "Train epoch: 2 [200/625]\tAccuracy: 88.44%\tLoss: 0.276232\n",
            "Train epoch: 2 [210/625]\tAccuracy: 89.06%\tLoss: 0.254157\n",
            "Train epoch: 2 [220/625]\tAccuracy: 88.44%\tLoss: 0.272099\n",
            "Train epoch: 2 [230/625]\tAccuracy: 88.12%\tLoss: 0.275285\n",
            "Train epoch: 2 [240/625]\tAccuracy: 91.88%\tLoss: 0.247788\n",
            "Train epoch: 2 [250/625]\tAccuracy: 87.50%\tLoss: 0.269928\n",
            "Train epoch: 2 [260/625]\tAccuracy: 86.25%\tLoss: 0.259247\n",
            "Train epoch: 2 [270/625]\tAccuracy: 84.38%\tLoss: 0.316422\n",
            "Train epoch: 2 [280/625]\tAccuracy: 86.56%\tLoss: 0.303492\n",
            "Train epoch: 2 [290/625]\tAccuracy: 88.12%\tLoss: 0.284597\n",
            "Train epoch: 2 [300/625]\tAccuracy: 83.44%\tLoss: 0.305763\n",
            "Train epoch: 2 [310/625]\tAccuracy: 87.19%\tLoss: 0.270321\n",
            "Train epoch: 2 [320/625]\tAccuracy: 87.81%\tLoss: 0.268961\n",
            "Train epoch: 2 [330/625]\tAccuracy: 85.62%\tLoss: 0.291264\n",
            "Train epoch: 2 [340/625]\tAccuracy: 89.38%\tLoss: 0.239426\n",
            "Train epoch: 2 [350/625]\tAccuracy: 85.31%\tLoss: 0.316547\n",
            "Train epoch: 2 [360/625]\tAccuracy: 87.50%\tLoss: 0.292853\n",
            "Train epoch: 2 [370/625]\tAccuracy: 89.69%\tLoss: 0.256705\n",
            "Train epoch: 2 [380/625]\tAccuracy: 85.62%\tLoss: 0.313689\n",
            "Train epoch: 2 [390/625]\tAccuracy: 88.75%\tLoss: 0.243179\n",
            "Train epoch: 2 [400/625]\tAccuracy: 88.12%\tLoss: 0.266228\n",
            "Train epoch: 2 [410/625]\tAccuracy: 90.62%\tLoss: 0.224588\n",
            "Train epoch: 2 [420/625]\tAccuracy: 88.12%\tLoss: 0.266590\n",
            "Train epoch: 2 [430/625]\tAccuracy: 90.00%\tLoss: 0.226356\n",
            "Train epoch: 2 [440/625]\tAccuracy: 89.69%\tLoss: 0.280579\n",
            "Train epoch: 2 [450/625]\tAccuracy: 89.06%\tLoss: 0.245349\n",
            "Train epoch: 2 [460/625]\tAccuracy: 90.94%\tLoss: 0.237988\n",
            "Train epoch: 2 [470/625]\tAccuracy: 89.69%\tLoss: 0.243262\n",
            "Train epoch: 2 [480/625]\tAccuracy: 88.44%\tLoss: 0.262855\n",
            "Train epoch: 2 [490/625]\tAccuracy: 88.12%\tLoss: 0.259724\n",
            "Train epoch: 2 [500/625]\tAccuracy: 89.38%\tLoss: 0.276003\n",
            "Train epoch: 2 [510/625]\tAccuracy: 88.75%\tLoss: 0.269746\n",
            "Train epoch: 2 [520/625]\tAccuracy: 86.25%\tLoss: 0.277259\n",
            "Train epoch: 2 [530/625]\tAccuracy: 85.62%\tLoss: 0.309497\n",
            "Train epoch: 2 [540/625]\tAccuracy: 88.44%\tLoss: 0.279866\n",
            "Train epoch: 2 [550/625]\tAccuracy: 88.12%\tLoss: 0.282524\n",
            "Train epoch: 2 [560/625]\tAccuracy: 89.69%\tLoss: 0.272599\n",
            "Train epoch: 2 [570/625]\tAccuracy: 86.25%\tLoss: 0.304770\n",
            "Train epoch: 2 [580/625]\tAccuracy: 86.56%\tLoss: 0.305417\n",
            "Train epoch: 2 [590/625]\tAccuracy: 90.00%\tLoss: 0.270083\n",
            "Train epoch: 2 [600/625]\tAccuracy: 87.81%\tLoss: 0.288912\n",
            "Train epoch: 2 [610/625]\tAccuracy: 87.50%\tLoss: 0.299018\n",
            "Train epoch: 2 [620/625]\tAccuracy: 86.56%\tLoss: 0.347838\n",
            "Test set: Loss: 0.6382, Accuracy: 67.77%)\n",
            "Train epoch: 3 [10/625]\tAccuracy: 86.88%\tLoss: 0.280639\n",
            "Train epoch: 3 [20/625]\tAccuracy: 91.88%\tLoss: 0.233205\n",
            "Train epoch: 3 [30/625]\tAccuracy: 90.94%\tLoss: 0.218799\n",
            "Train epoch: 3 [40/625]\tAccuracy: 89.06%\tLoss: 0.228782\n",
            "Train epoch: 3 [50/625]\tAccuracy: 89.06%\tLoss: 0.244964\n",
            "Train epoch: 3 [60/625]\tAccuracy: 85.94%\tLoss: 0.296760\n",
            "Train epoch: 3 [70/625]\tAccuracy: 89.06%\tLoss: 0.271274\n",
            "Train epoch: 3 [80/625]\tAccuracy: 90.00%\tLoss: 0.247515\n",
            "Train epoch: 3 [90/625]\tAccuracy: 89.69%\tLoss: 0.228726\n",
            "Train epoch: 3 [100/625]\tAccuracy: 89.69%\tLoss: 0.279176\n",
            "Train epoch: 3 [110/625]\tAccuracy: 88.44%\tLoss: 0.239029\n",
            "Train epoch: 3 [120/625]\tAccuracy: 92.81%\tLoss: 0.203397\n",
            "Train epoch: 3 [130/625]\tAccuracy: 89.38%\tLoss: 0.279434\n",
            "Train epoch: 3 [140/625]\tAccuracy: 89.06%\tLoss: 0.258052\n",
            "Train epoch: 3 [150/625]\tAccuracy: 88.75%\tLoss: 0.283471\n",
            "Train epoch: 3 [160/625]\tAccuracy: 90.62%\tLoss: 0.264831\n",
            "Train epoch: 3 [170/625]\tAccuracy: 84.69%\tLoss: 0.315710\n",
            "Train epoch: 3 [180/625]\tAccuracy: 83.75%\tLoss: 0.357361\n",
            "Train epoch: 3 [190/625]\tAccuracy: 88.44%\tLoss: 0.282994\n",
            "Train epoch: 3 [200/625]\tAccuracy: 87.50%\tLoss: 0.267065\n",
            "Train epoch: 3 [210/625]\tAccuracy: 84.69%\tLoss: 0.293906\n",
            "Train epoch: 3 [220/625]\tAccuracy: 88.75%\tLoss: 0.263616\n",
            "Train epoch: 3 [230/625]\tAccuracy: 85.94%\tLoss: 0.325659\n",
            "Train epoch: 3 [240/625]\tAccuracy: 87.50%\tLoss: 0.283303\n",
            "Train epoch: 3 [250/625]\tAccuracy: 85.94%\tLoss: 0.284163\n",
            "Train epoch: 3 [260/625]\tAccuracy: 89.38%\tLoss: 0.237983\n",
            "Train epoch: 3 [270/625]\tAccuracy: 86.56%\tLoss: 0.298434\n",
            "Train epoch: 3 [280/625]\tAccuracy: 88.75%\tLoss: 0.288290\n",
            "Train epoch: 3 [290/625]\tAccuracy: 88.12%\tLoss: 0.261014\n",
            "Train epoch: 3 [300/625]\tAccuracy: 89.38%\tLoss: 0.264533\n",
            "Train epoch: 3 [310/625]\tAccuracy: 85.62%\tLoss: 0.296715\n",
            "Train epoch: 3 [320/625]\tAccuracy: 87.81%\tLoss: 0.260315\n",
            "Train epoch: 3 [330/625]\tAccuracy: 90.00%\tLoss: 0.241326\n",
            "Train epoch: 3 [340/625]\tAccuracy: 87.50%\tLoss: 0.293883\n",
            "Train epoch: 3 [350/625]\tAccuracy: 88.44%\tLoss: 0.264570\n",
            "Train epoch: 3 [360/625]\tAccuracy: 89.69%\tLoss: 0.230214\n",
            "Train epoch: 3 [370/625]\tAccuracy: 90.00%\tLoss: 0.240993\n",
            "Train epoch: 3 [380/625]\tAccuracy: 91.56%\tLoss: 0.251610\n",
            "Train epoch: 3 [390/625]\tAccuracy: 89.06%\tLoss: 0.275250\n",
            "Train epoch: 3 [400/625]\tAccuracy: 84.69%\tLoss: 0.315320\n",
            "Train epoch: 3 [410/625]\tAccuracy: 86.88%\tLoss: 0.303811\n",
            "Train epoch: 3 [420/625]\tAccuracy: 89.06%\tLoss: 0.269716\n",
            "Train epoch: 3 [430/625]\tAccuracy: 87.50%\tLoss: 0.279424\n",
            "Train epoch: 3 [440/625]\tAccuracy: 89.69%\tLoss: 0.247710\n",
            "Train epoch: 3 [450/625]\tAccuracy: 89.38%\tLoss: 0.263498\n",
            "Train epoch: 3 [460/625]\tAccuracy: 85.00%\tLoss: 0.328926\n",
            "Train epoch: 3 [470/625]\tAccuracy: 86.88%\tLoss: 0.286073\n",
            "Train epoch: 3 [480/625]\tAccuracy: 89.69%\tLoss: 0.240555\n",
            "Train epoch: 3 [490/625]\tAccuracy: 86.88%\tLoss: 0.301810\n",
            "Train epoch: 3 [500/625]\tAccuracy: 87.81%\tLoss: 0.257993\n",
            "Train epoch: 3 [510/625]\tAccuracy: 88.44%\tLoss: 0.281211\n",
            "Train epoch: 3 [520/625]\tAccuracy: 89.06%\tLoss: 0.272117\n",
            "Train epoch: 3 [530/625]\tAccuracy: 85.00%\tLoss: 0.312302\n",
            "Train epoch: 3 [540/625]\tAccuracy: 88.12%\tLoss: 0.267300\n",
            "Train epoch: 3 [550/625]\tAccuracy: 83.44%\tLoss: 0.311468\n",
            "Train epoch: 3 [560/625]\tAccuracy: 88.75%\tLoss: 0.259726\n",
            "Train epoch: 3 [570/625]\tAccuracy: 88.75%\tLoss: 0.264124\n",
            "Train epoch: 3 [580/625]\tAccuracy: 90.00%\tLoss: 0.235832\n",
            "Train epoch: 3 [590/625]\tAccuracy: 89.06%\tLoss: 0.267621\n",
            "Train epoch: 3 [600/625]\tAccuracy: 87.19%\tLoss: 0.283525\n",
            "Train epoch: 3 [610/625]\tAccuracy: 87.81%\tLoss: 0.265885\n",
            "Train epoch: 3 [620/625]\tAccuracy: 88.44%\tLoss: 0.242791\n",
            "Test set: Loss: 0.6282, Accuracy: 68.05%)\n",
            "Train epoch: 4 [10/625]\tAccuracy: 90.00%\tLoss: 0.271931\n",
            "Train epoch: 4 [20/625]\tAccuracy: 90.94%\tLoss: 0.232623\n",
            "Train epoch: 4 [30/625]\tAccuracy: 84.69%\tLoss: 0.335516\n",
            "Train epoch: 4 [40/625]\tAccuracy: 87.81%\tLoss: 0.261581\n",
            "Train epoch: 4 [50/625]\tAccuracy: 87.81%\tLoss: 0.282531\n",
            "Train epoch: 4 [60/625]\tAccuracy: 88.44%\tLoss: 0.269458\n",
            "Train epoch: 4 [70/625]\tAccuracy: 90.31%\tLoss: 0.234351\n",
            "Train epoch: 4 [80/625]\tAccuracy: 88.75%\tLoss: 0.230233\n",
            "Train epoch: 4 [90/625]\tAccuracy: 85.31%\tLoss: 0.328546\n",
            "Train epoch: 4 [100/625]\tAccuracy: 85.00%\tLoss: 0.316945\n",
            "Train epoch: 4 [110/625]\tAccuracy: 85.62%\tLoss: 0.310645\n",
            "Train epoch: 4 [120/625]\tAccuracy: 85.62%\tLoss: 0.279042\n",
            "Train epoch: 4 [130/625]\tAccuracy: 84.69%\tLoss: 0.307800\n",
            "Train epoch: 4 [140/625]\tAccuracy: 92.19%\tLoss: 0.212816\n",
            "Train epoch: 4 [150/625]\tAccuracy: 87.19%\tLoss: 0.277826\n",
            "Train epoch: 4 [160/625]\tAccuracy: 88.12%\tLoss: 0.269881\n",
            "Train epoch: 4 [170/625]\tAccuracy: 86.88%\tLoss: 0.288097\n",
            "Train epoch: 4 [180/625]\tAccuracy: 91.56%\tLoss: 0.216519\n",
            "Train epoch: 4 [190/625]\tAccuracy: 90.62%\tLoss: 0.280505\n",
            "Train epoch: 4 [200/625]\tAccuracy: 88.12%\tLoss: 0.239959\n",
            "Train epoch: 4 [210/625]\tAccuracy: 89.06%\tLoss: 0.253931\n",
            "Train epoch: 4 [220/625]\tAccuracy: 90.94%\tLoss: 0.226143\n",
            "Train epoch: 4 [230/625]\tAccuracy: 90.31%\tLoss: 0.228970\n",
            "Train epoch: 4 [240/625]\tAccuracy: 89.38%\tLoss: 0.286297\n",
            "Train epoch: 4 [250/625]\tAccuracy: 88.75%\tLoss: 0.254872\n",
            "Train epoch: 4 [260/625]\tAccuracy: 91.56%\tLoss: 0.226958\n",
            "Train epoch: 4 [270/625]\tAccuracy: 90.94%\tLoss: 0.239994\n",
            "Train epoch: 4 [280/625]\tAccuracy: 88.12%\tLoss: 0.243014\n",
            "Train epoch: 4 [290/625]\tAccuracy: 89.38%\tLoss: 0.237305\n",
            "Train epoch: 4 [300/625]\tAccuracy: 89.06%\tLoss: 0.273092\n",
            "Train epoch: 4 [310/625]\tAccuracy: 87.50%\tLoss: 0.257505\n",
            "Train epoch: 4 [320/625]\tAccuracy: 89.38%\tLoss: 0.278820\n",
            "Train epoch: 4 [330/625]\tAccuracy: 87.50%\tLoss: 0.282949\n",
            "Train epoch: 4 [340/625]\tAccuracy: 89.69%\tLoss: 0.248307\n",
            "Train epoch: 4 [350/625]\tAccuracy: 87.50%\tLoss: 0.282840\n",
            "Train epoch: 4 [360/625]\tAccuracy: 86.56%\tLoss: 0.276652\n",
            "Train epoch: 4 [370/625]\tAccuracy: 88.75%\tLoss: 0.264850\n",
            "Train epoch: 4 [380/625]\tAccuracy: 86.88%\tLoss: 0.281895\n",
            "Train epoch: 4 [390/625]\tAccuracy: 86.25%\tLoss: 0.289735\n",
            "Train epoch: 4 [400/625]\tAccuracy: 87.81%\tLoss: 0.277955\n",
            "Train epoch: 4 [410/625]\tAccuracy: 87.19%\tLoss: 0.266606\n",
            "Train epoch: 4 [420/625]\tAccuracy: 87.50%\tLoss: 0.266624\n",
            "Train epoch: 4 [430/625]\tAccuracy: 87.50%\tLoss: 0.261030\n",
            "Train epoch: 4 [440/625]\tAccuracy: 89.38%\tLoss: 0.274192\n",
            "Train epoch: 4 [450/625]\tAccuracy: 88.75%\tLoss: 0.254597\n",
            "Train epoch: 4 [460/625]\tAccuracy: 89.69%\tLoss: 0.244767\n",
            "Train epoch: 4 [470/625]\tAccuracy: 89.06%\tLoss: 0.251041\n",
            "Train epoch: 4 [480/625]\tAccuracy: 85.31%\tLoss: 0.291535\n",
            "Train epoch: 4 [490/625]\tAccuracy: 89.38%\tLoss: 0.266500\n",
            "Train epoch: 4 [500/625]\tAccuracy: 90.94%\tLoss: 0.212975\n",
            "Train epoch: 4 [510/625]\tAccuracy: 90.31%\tLoss: 0.271514\n",
            "Train epoch: 4 [520/625]\tAccuracy: 85.31%\tLoss: 0.280599\n",
            "Train epoch: 4 [530/625]\tAccuracy: 89.38%\tLoss: 0.248387\n",
            "Train epoch: 4 [540/625]\tAccuracy: 88.44%\tLoss: 0.253568\n",
            "Train epoch: 4 [550/625]\tAccuracy: 89.38%\tLoss: 0.248012\n",
            "Train epoch: 4 [560/625]\tAccuracy: 87.81%\tLoss: 0.260255\n",
            "Train epoch: 4 [570/625]\tAccuracy: 87.81%\tLoss: 0.277941\n",
            "Train epoch: 4 [580/625]\tAccuracy: 85.62%\tLoss: 0.311374\n",
            "Train epoch: 4 [590/625]\tAccuracy: 87.19%\tLoss: 0.271150\n",
            "Train epoch: 4 [600/625]\tAccuracy: 89.69%\tLoss: 0.233501\n",
            "Train epoch: 4 [610/625]\tAccuracy: 90.00%\tLoss: 0.223192\n",
            "Train epoch: 4 [620/625]\tAccuracy: 89.06%\tLoss: 0.254710\n",
            "Test set: Loss: 0.9486, Accuracy: 65.41%)\n",
            "Train epoch: 5 [10/625]\tAccuracy: 86.88%\tLoss: 0.272791\n",
            "Train epoch: 5 [20/625]\tAccuracy: 83.75%\tLoss: 0.307443\n",
            "Train epoch: 5 [30/625]\tAccuracy: 87.19%\tLoss: 0.312728\n",
            "Train epoch: 5 [40/625]\tAccuracy: 86.88%\tLoss: 0.292487\n",
            "Train epoch: 5 [50/625]\tAccuracy: 88.75%\tLoss: 0.301617\n",
            "Train epoch: 5 [60/625]\tAccuracy: 91.25%\tLoss: 0.238795\n",
            "Train epoch: 5 [70/625]\tAccuracy: 88.75%\tLoss: 0.246801\n",
            "Train epoch: 5 [80/625]\tAccuracy: 86.88%\tLoss: 0.300109\n",
            "Train epoch: 5 [90/625]\tAccuracy: 87.81%\tLoss: 0.254779\n",
            "Train epoch: 5 [100/625]\tAccuracy: 85.94%\tLoss: 0.283213\n",
            "Train epoch: 5 [110/625]\tAccuracy: 90.00%\tLoss: 0.238467\n",
            "Train epoch: 5 [120/625]\tAccuracy: 89.06%\tLoss: 0.255454\n",
            "Train epoch: 5 [130/625]\tAccuracy: 89.38%\tLoss: 0.231469\n",
            "Train epoch: 5 [140/625]\tAccuracy: 90.31%\tLoss: 0.251642\n",
            "Train epoch: 5 [150/625]\tAccuracy: 88.75%\tLoss: 0.250693\n",
            "Train epoch: 5 [160/625]\tAccuracy: 89.69%\tLoss: 0.240243\n",
            "Train epoch: 5 [170/625]\tAccuracy: 89.06%\tLoss: 0.249468\n",
            "Train epoch: 5 [180/625]\tAccuracy: 89.69%\tLoss: 0.230398\n",
            "Train epoch: 5 [190/625]\tAccuracy: 89.06%\tLoss: 0.254799\n",
            "Train epoch: 5 [200/625]\tAccuracy: 86.56%\tLoss: 0.229367\n",
            "Train epoch: 5 [210/625]\tAccuracy: 88.12%\tLoss: 0.264174\n",
            "Train epoch: 5 [220/625]\tAccuracy: 86.88%\tLoss: 0.256918\n",
            "Train epoch: 5 [230/625]\tAccuracy: 90.00%\tLoss: 0.231862\n",
            "Train epoch: 5 [240/625]\tAccuracy: 89.06%\tLoss: 0.281786\n",
            "Train epoch: 5 [250/625]\tAccuracy: 87.19%\tLoss: 0.245166\n",
            "Train epoch: 5 [260/625]\tAccuracy: 85.31%\tLoss: 0.309683\n",
            "Train epoch: 5 [270/625]\tAccuracy: 89.06%\tLoss: 0.233281\n",
            "Train epoch: 5 [280/625]\tAccuracy: 84.06%\tLoss: 0.302364\n",
            "Train epoch: 5 [290/625]\tAccuracy: 90.94%\tLoss: 0.210146\n",
            "Train epoch: 5 [300/625]\tAccuracy: 88.12%\tLoss: 0.263910\n",
            "Train epoch: 5 [310/625]\tAccuracy: 86.88%\tLoss: 0.305636\n",
            "Train epoch: 5 [320/625]\tAccuracy: 89.69%\tLoss: 0.259546\n",
            "Train epoch: 5 [330/625]\tAccuracy: 86.88%\tLoss: 0.285311\n",
            "Train epoch: 5 [340/625]\tAccuracy: 87.19%\tLoss: 0.270301\n",
            "Train epoch: 5 [350/625]\tAccuracy: 87.19%\tLoss: 0.254218\n",
            "Train epoch: 5 [360/625]\tAccuracy: 89.69%\tLoss: 0.236237\n",
            "Train epoch: 5 [370/625]\tAccuracy: 89.06%\tLoss: 0.267462\n",
            "Train epoch: 5 [380/625]\tAccuracy: 90.31%\tLoss: 0.249723\n",
            "Train epoch: 5 [390/625]\tAccuracy: 90.31%\tLoss: 0.240835\n",
            "Train epoch: 5 [400/625]\tAccuracy: 88.12%\tLoss: 0.279868\n",
            "Train epoch: 5 [410/625]\tAccuracy: 86.56%\tLoss: 0.280068\n",
            "Train epoch: 5 [420/625]\tAccuracy: 89.38%\tLoss: 0.256959\n",
            "Train epoch: 5 [430/625]\tAccuracy: 88.44%\tLoss: 0.246744\n",
            "Train epoch: 5 [440/625]\tAccuracy: 87.81%\tLoss: 0.299774\n",
            "Train epoch: 5 [450/625]\tAccuracy: 88.12%\tLoss: 0.267774\n",
            "Train epoch: 5 [460/625]\tAccuracy: 90.62%\tLoss: 0.235815\n",
            "Train epoch: 5 [470/625]\tAccuracy: 85.94%\tLoss: 0.273212\n",
            "Train epoch: 5 [480/625]\tAccuracy: 86.25%\tLoss: 0.267594\n",
            "Train epoch: 5 [490/625]\tAccuracy: 89.06%\tLoss: 0.284688\n",
            "Train epoch: 5 [500/625]\tAccuracy: 87.19%\tLoss: 0.267114\n",
            "Train epoch: 5 [510/625]\tAccuracy: 89.06%\tLoss: 0.291937\n",
            "Train epoch: 5 [520/625]\tAccuracy: 87.81%\tLoss: 0.285451\n",
            "Train epoch: 5 [530/625]\tAccuracy: 87.81%\tLoss: 0.259135\n",
            "Train epoch: 5 [540/625]\tAccuracy: 86.25%\tLoss: 0.309490\n",
            "Train epoch: 5 [550/625]\tAccuracy: 92.19%\tLoss: 0.226562\n",
            "Train epoch: 5 [560/625]\tAccuracy: 90.31%\tLoss: 0.245261\n",
            "Train epoch: 5 [570/625]\tAccuracy: 88.75%\tLoss: 0.231802\n",
            "Train epoch: 5 [580/625]\tAccuracy: 88.44%\tLoss: 0.274857\n",
            "Train epoch: 5 [590/625]\tAccuracy: 86.25%\tLoss: 0.296020\n",
            "Train epoch: 5 [600/625]\tAccuracy: 88.12%\tLoss: 0.270528\n",
            "Train epoch: 5 [610/625]\tAccuracy: 86.56%\tLoss: 0.251219\n",
            "Train epoch: 5 [620/625]\tAccuracy: 88.12%\tLoss: 0.271451\n",
            "Test set: Loss: 0.6860, Accuracy: 65.45%)\n",
            "Train epoch: 6 [10/625]\tAccuracy: 89.38%\tLoss: 0.249801\n",
            "Train epoch: 6 [20/625]\tAccuracy: 89.69%\tLoss: 0.253236\n",
            "Train epoch: 6 [30/625]\tAccuracy: 89.69%\tLoss: 0.255152\n",
            "Train epoch: 6 [40/625]\tAccuracy: 88.12%\tLoss: 0.244999\n",
            "Train epoch: 6 [50/625]\tAccuracy: 89.69%\tLoss: 0.252428\n",
            "Train epoch: 6 [60/625]\tAccuracy: 90.94%\tLoss: 0.235300\n",
            "Train epoch: 6 [70/625]\tAccuracy: 91.56%\tLoss: 0.256134\n",
            "Train epoch: 6 [80/625]\tAccuracy: 90.31%\tLoss: 0.299761\n",
            "Train epoch: 6 [90/625]\tAccuracy: 83.75%\tLoss: 0.321076\n",
            "Train epoch: 6 [100/625]\tAccuracy: 88.12%\tLoss: 0.283583\n",
            "Train epoch: 6 [110/625]\tAccuracy: 90.94%\tLoss: 0.230853\n",
            "Train epoch: 6 [120/625]\tAccuracy: 85.62%\tLoss: 0.296290\n",
            "Train epoch: 6 [130/625]\tAccuracy: 89.38%\tLoss: 0.262564\n",
            "Train epoch: 6 [140/625]\tAccuracy: 89.06%\tLoss: 0.270387\n",
            "Train epoch: 6 [150/625]\tAccuracy: 85.00%\tLoss: 0.302829\n",
            "Train epoch: 6 [160/625]\tAccuracy: 86.56%\tLoss: 0.284692\n",
            "Train epoch: 6 [170/625]\tAccuracy: 91.25%\tLoss: 0.213401\n",
            "Train epoch: 6 [180/625]\tAccuracy: 89.69%\tLoss: 0.228618\n",
            "Train epoch: 6 [190/625]\tAccuracy: 89.06%\tLoss: 0.259291\n",
            "Train epoch: 6 [200/625]\tAccuracy: 90.62%\tLoss: 0.248556\n",
            "Train epoch: 6 [210/625]\tAccuracy: 86.88%\tLoss: 0.272279\n",
            "Train epoch: 6 [220/625]\tAccuracy: 88.12%\tLoss: 0.311462\n",
            "Train epoch: 6 [230/625]\tAccuracy: 88.44%\tLoss: 0.231892\n",
            "Train epoch: 6 [240/625]\tAccuracy: 88.75%\tLoss: 0.239695\n",
            "Train epoch: 6 [250/625]\tAccuracy: 90.31%\tLoss: 0.239040\n",
            "Train epoch: 6 [260/625]\tAccuracy: 90.00%\tLoss: 0.232461\n",
            "Train epoch: 6 [270/625]\tAccuracy: 88.12%\tLoss: 0.284426\n",
            "Train epoch: 6 [280/625]\tAccuracy: 87.50%\tLoss: 0.279966\n",
            "Train epoch: 6 [290/625]\tAccuracy: 90.31%\tLoss: 0.228528\n",
            "Train epoch: 6 [300/625]\tAccuracy: 89.06%\tLoss: 0.255833\n",
            "Train epoch: 6 [310/625]\tAccuracy: 88.12%\tLoss: 0.280611\n",
            "Train epoch: 6 [320/625]\tAccuracy: 90.62%\tLoss: 0.250973\n",
            "Train epoch: 6 [330/625]\tAccuracy: 91.56%\tLoss: 0.239742\n",
            "Train epoch: 6 [340/625]\tAccuracy: 87.19%\tLoss: 0.284675\n",
            "Train epoch: 6 [350/625]\tAccuracy: 89.06%\tLoss: 0.246368\n",
            "Train epoch: 6 [360/625]\tAccuracy: 89.69%\tLoss: 0.254833\n",
            "Train epoch: 6 [370/625]\tAccuracy: 89.38%\tLoss: 0.265339\n",
            "Train epoch: 6 [380/625]\tAccuracy: 85.31%\tLoss: 0.305656\n",
            "Train epoch: 6 [390/625]\tAccuracy: 85.94%\tLoss: 0.289927\n",
            "Train epoch: 6 [400/625]\tAccuracy: 84.38%\tLoss: 0.311164\n",
            "Train epoch: 6 [410/625]\tAccuracy: 86.56%\tLoss: 0.285569\n",
            "Train epoch: 6 [420/625]\tAccuracy: 87.50%\tLoss: 0.276502\n",
            "Train epoch: 6 [430/625]\tAccuracy: 85.31%\tLoss: 0.312384\n",
            "Train epoch: 6 [440/625]\tAccuracy: 90.31%\tLoss: 0.223650\n",
            "Train epoch: 6 [450/625]\tAccuracy: 87.50%\tLoss: 0.270049\n",
            "Train epoch: 6 [460/625]\tAccuracy: 90.00%\tLoss: 0.239003\n",
            "Train epoch: 6 [470/625]\tAccuracy: 87.50%\tLoss: 0.287987\n",
            "Train epoch: 6 [480/625]\tAccuracy: 93.12%\tLoss: 0.209215\n",
            "Train epoch: 6 [490/625]\tAccuracy: 87.81%\tLoss: 0.277466\n",
            "Train epoch: 6 [500/625]\tAccuracy: 86.56%\tLoss: 0.262722\n",
            "Train epoch: 6 [510/625]\tAccuracy: 85.00%\tLoss: 0.306185\n",
            "Train epoch: 6 [520/625]\tAccuracy: 86.25%\tLoss: 0.290847\n",
            "Train epoch: 6 [530/625]\tAccuracy: 89.38%\tLoss: 0.250056\n",
            "Train epoch: 6 [540/625]\tAccuracy: 91.56%\tLoss: 0.215545\n",
            "Train epoch: 6 [550/625]\tAccuracy: 89.38%\tLoss: 0.245561\n",
            "Train epoch: 6 [560/625]\tAccuracy: 91.56%\tLoss: 0.225524\n",
            "Train epoch: 6 [570/625]\tAccuracy: 88.12%\tLoss: 0.259824\n",
            "Train epoch: 6 [580/625]\tAccuracy: 89.38%\tLoss: 0.237587\n",
            "Train epoch: 6 [590/625]\tAccuracy: 90.00%\tLoss: 0.233650\n",
            "Train epoch: 6 [600/625]\tAccuracy: 89.06%\tLoss: 0.241898\n",
            "Train epoch: 6 [610/625]\tAccuracy: 90.00%\tLoss: 0.284801\n",
            "Train epoch: 6 [620/625]\tAccuracy: 89.38%\tLoss: 0.248766\n",
            "Test set: Loss: 0.8309, Accuracy: 62.56%)\n",
            "Train epoch: 7 [10/625]\tAccuracy: 90.00%\tLoss: 0.262548\n",
            "Train epoch: 7 [20/625]\tAccuracy: 87.81%\tLoss: 0.261047\n",
            "Train epoch: 7 [30/625]\tAccuracy: 89.06%\tLoss: 0.246063\n",
            "Train epoch: 7 [40/625]\tAccuracy: 90.00%\tLoss: 0.240847\n",
            "Train epoch: 7 [50/625]\tAccuracy: 86.56%\tLoss: 0.272235\n",
            "Train epoch: 7 [60/625]\tAccuracy: 90.62%\tLoss: 0.243631\n",
            "Train epoch: 7 [70/625]\tAccuracy: 90.62%\tLoss: 0.236133\n",
            "Train epoch: 7 [80/625]\tAccuracy: 90.94%\tLoss: 0.241165\n",
            "Train epoch: 7 [90/625]\tAccuracy: 88.44%\tLoss: 0.279899\n",
            "Train epoch: 7 [100/625]\tAccuracy: 90.94%\tLoss: 0.230212\n",
            "Train epoch: 7 [110/625]\tAccuracy: 89.38%\tLoss: 0.264290\n",
            "Train epoch: 7 [120/625]\tAccuracy: 87.19%\tLoss: 0.285938\n",
            "Train epoch: 7 [130/625]\tAccuracy: 87.50%\tLoss: 0.249778\n",
            "Train epoch: 7 [140/625]\tAccuracy: 89.69%\tLoss: 0.230230\n",
            "Train epoch: 7 [150/625]\tAccuracy: 87.81%\tLoss: 0.260094\n",
            "Train epoch: 7 [160/625]\tAccuracy: 87.19%\tLoss: 0.271869\n",
            "Train epoch: 7 [170/625]\tAccuracy: 85.62%\tLoss: 0.295822\n",
            "Train epoch: 7 [180/625]\tAccuracy: 90.62%\tLoss: 0.226562\n",
            "Train epoch: 7 [190/625]\tAccuracy: 87.19%\tLoss: 0.258982\n",
            "Train epoch: 7 [200/625]\tAccuracy: 90.62%\tLoss: 0.230861\n",
            "Train epoch: 7 [210/625]\tAccuracy: 90.00%\tLoss: 0.248035\n",
            "Train epoch: 7 [220/625]\tAccuracy: 90.00%\tLoss: 0.250662\n",
            "Train epoch: 7 [230/625]\tAccuracy: 88.44%\tLoss: 0.235756\n",
            "Train epoch: 7 [240/625]\tAccuracy: 90.00%\tLoss: 0.230572\n",
            "Train epoch: 7 [250/625]\tAccuracy: 85.31%\tLoss: 0.262105\n",
            "Train epoch: 7 [260/625]\tAccuracy: 86.25%\tLoss: 0.276080\n",
            "Train epoch: 7 [270/625]\tAccuracy: 91.88%\tLoss: 0.216114\n",
            "Train epoch: 7 [280/625]\tAccuracy: 89.69%\tLoss: 0.249413\n",
            "Train epoch: 7 [290/625]\tAccuracy: 90.62%\tLoss: 0.249914\n",
            "Train epoch: 7 [300/625]\tAccuracy: 90.00%\tLoss: 0.263042\n",
            "Train epoch: 7 [310/625]\tAccuracy: 90.94%\tLoss: 0.219141\n",
            "Train epoch: 7 [320/625]\tAccuracy: 87.50%\tLoss: 0.271791\n",
            "Train epoch: 7 [330/625]\tAccuracy: 90.62%\tLoss: 0.229105\n",
            "Train epoch: 7 [340/625]\tAccuracy: 86.56%\tLoss: 0.290071\n",
            "Train epoch: 7 [350/625]\tAccuracy: 86.56%\tLoss: 0.268702\n",
            "Train epoch: 7 [360/625]\tAccuracy: 90.00%\tLoss: 0.262149\n",
            "Train epoch: 7 [370/625]\tAccuracy: 90.00%\tLoss: 0.254267\n",
            "Train epoch: 7 [380/625]\tAccuracy: 89.06%\tLoss: 0.234529\n",
            "Train epoch: 7 [390/625]\tAccuracy: 91.88%\tLoss: 0.231589\n",
            "Train epoch: 7 [400/625]\tAccuracy: 88.75%\tLoss: 0.258026\n",
            "Train epoch: 7 [410/625]\tAccuracy: 88.12%\tLoss: 0.265257\n",
            "Train epoch: 7 [420/625]\tAccuracy: 85.62%\tLoss: 0.298869\n",
            "Train epoch: 7 [430/625]\tAccuracy: 85.94%\tLoss: 0.280799\n",
            "Train epoch: 7 [440/625]\tAccuracy: 88.44%\tLoss: 0.277417\n",
            "Train epoch: 7 [450/625]\tAccuracy: 88.12%\tLoss: 0.272051\n",
            "Train epoch: 7 [460/625]\tAccuracy: 88.44%\tLoss: 0.246202\n",
            "Train epoch: 7 [470/625]\tAccuracy: 88.75%\tLoss: 0.294135\n",
            "Train epoch: 7 [480/625]\tAccuracy: 86.25%\tLoss: 0.285956\n",
            "Train epoch: 7 [490/625]\tAccuracy: 87.81%\tLoss: 0.301511\n",
            "Train epoch: 7 [500/625]\tAccuracy: 91.56%\tLoss: 0.213684\n",
            "Train epoch: 7 [510/625]\tAccuracy: 88.12%\tLoss: 0.266915\n",
            "Train epoch: 7 [520/625]\tAccuracy: 88.75%\tLoss: 0.246474\n",
            "Train epoch: 7 [530/625]\tAccuracy: 90.31%\tLoss: 0.222917\n",
            "Train epoch: 7 [540/625]\tAccuracy: 90.94%\tLoss: 0.240152\n",
            "Train epoch: 7 [550/625]\tAccuracy: 88.44%\tLoss: 0.246067\n",
            "Train epoch: 7 [560/625]\tAccuracy: 89.06%\tLoss: 0.246996\n",
            "Train epoch: 7 [570/625]\tAccuracy: 88.44%\tLoss: 0.257806\n",
            "Train epoch: 7 [580/625]\tAccuracy: 90.00%\tLoss: 0.222799\n",
            "Train epoch: 7 [590/625]\tAccuracy: 87.50%\tLoss: 0.290726\n",
            "Train epoch: 7 [600/625]\tAccuracy: 88.44%\tLoss: 0.304566\n",
            "Train epoch: 7 [610/625]\tAccuracy: 89.06%\tLoss: 0.251280\n",
            "Train epoch: 7 [620/625]\tAccuracy: 85.00%\tLoss: 0.280766\n",
            "Test set: Loss: 0.9059, Accuracy: 66.70%)\n",
            "Train epoch: 8 [10/625]\tAccuracy: 84.38%\tLoss: 0.295395\n",
            "Train epoch: 8 [20/625]\tAccuracy: 85.31%\tLoss: 0.316049\n",
            "Train epoch: 8 [30/625]\tAccuracy: 85.00%\tLoss: 0.310199\n",
            "Train epoch: 8 [40/625]\tAccuracy: 87.81%\tLoss: 0.262756\n",
            "Train epoch: 8 [50/625]\tAccuracy: 87.50%\tLoss: 0.269995\n",
            "Train epoch: 8 [60/625]\tAccuracy: 88.12%\tLoss: 0.251690\n",
            "Train epoch: 8 [70/625]\tAccuracy: 89.38%\tLoss: 0.252975\n",
            "Train epoch: 8 [80/625]\tAccuracy: 86.56%\tLoss: 0.296944\n",
            "Train epoch: 8 [90/625]\tAccuracy: 87.50%\tLoss: 0.292153\n",
            "Train epoch: 8 [100/625]\tAccuracy: 89.06%\tLoss: 0.238070\n",
            "Train epoch: 8 [110/625]\tAccuracy: 86.88%\tLoss: 0.282749\n",
            "Train epoch: 8 [120/625]\tAccuracy: 85.62%\tLoss: 0.281638\n",
            "Train epoch: 8 [130/625]\tAccuracy: 88.44%\tLoss: 0.280809\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}